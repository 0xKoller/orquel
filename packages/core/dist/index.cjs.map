{"version":3,"sources":["../src/index.ts","../src/chunker.ts","../src/utils.ts","../src/hybrid.ts","../src/orquel.ts","../src/evaluation.ts","../src/benchmark.ts"],"sourcesContent":["export * from './types.js';\nexport * from './orquel.js';\nexport * from './chunker.js';\nexport * from './utils.js';\nexport * from './evaluation.js';\nexport * from './hybrid.js';\nexport * from './benchmark.js';","import type { Chunk, IngestSource } from './types.js';\nimport { createHash } from 'node:crypto';\n\nexport interface ChunkerOptions {\n  maxChunkSize?: number;\n  overlap?: number;\n  respectMarkdownHeadings?: boolean;\n}\n\nconst DEFAULT_OPTIONS: Required<ChunkerOptions> = {\n  maxChunkSize: 1200,\n  overlap: 150,\n  respectMarkdownHeadings: true,\n};\n\n/**\n * Default text chunking function with intelligent splitting\n * \n * Features:\n * - Configurable chunk size and overlap\n * - Markdown heading awareness \n * - Word boundary preservation\n * - Content deduplication by hash\n * \n * @param text - Input text to chunk\n * @param source - Source document information\n * @param options - Chunking configuration options\n * @returns Array of text chunks with metadata\n * \n * @example\n * ```typescript\n * const chunks = defaultChunker(\n *   '# Title\\nContent here...',\n *   { title: 'My Doc', kind: 'md' },\n *   { maxChunkSize: 1000, overlap: 100 }\n * );\n * ```\n */\nexport function defaultChunker(\n  text: string,\n  source: IngestSource,\n  options: ChunkerOptions = {}\n): Chunk[] {\n  const opts = { ...DEFAULT_OPTIONS, ...options };\n  \n  // Normalize text: trim whitespace, collapse repeated spaces, preserve code blocks\n  const normalized = normalizeText(text);\n  \n  if (normalized.length === 0) {\n    return [];\n  }\n  \n  if (normalized.length <= opts.maxChunkSize) {\n    return [createChunk(normalized, source, 0)];\n  }\n\n  const chunks: Chunk[] = [];\n  let chunkIndex = 0;\n\n  if (opts.respectMarkdownHeadings && source.kind === 'md') {\n    const sections = splitByMarkdownHeadings(normalized);\n    \n    for (const section of sections) {\n      if (section.length <= opts.maxChunkSize) {\n        chunks.push(createChunk(section, source, chunkIndex++));\n      } else {\n        const subChunks = splitTextIntoChunks(section, opts.maxChunkSize, opts.overlap);\n        for (const subChunk of subChunks) {\n          chunks.push(createChunk(subChunk, source, chunkIndex++));\n        }\n      }\n    }\n  } else {\n    const textChunks = splitTextIntoChunks(normalized, opts.maxChunkSize, opts.overlap);\n    for (const chunk of textChunks) {\n      chunks.push(createChunk(chunk, source, chunkIndex++));\n    }\n  }\n\n  return deduplicateChunks(chunks);\n}\n\nfunction normalizeText(text: string): string {\n  return text\n    .trim()\n    .replace(/\\r\\n/g, '\\n')\n    .replace(/[ \\t]+/g, ' ')\n    .replace(/\\n{3,}/g, '\\n\\n');\n}\n\nfunction splitByMarkdownHeadings(text: string): string[] {\n  const sections: string[] = [];\n  const lines = text.split('\\n');\n  let currentSection = '';\n  \n  for (const line of lines) {\n    if (line.match(/^#{1,6}\\s/)) {\n      if (currentSection.trim()) {\n        sections.push(currentSection.trim());\n      }\n      currentSection = line + '\\n';\n    } else {\n      currentSection += line + '\\n';\n    }\n  }\n  \n  if (currentSection.trim()) {\n    sections.push(currentSection.trim());\n  }\n  \n  return sections.filter(s => s.length > 0);\n}\n\nfunction splitTextIntoChunks(text: string, maxSize: number, overlap: number): string[] {\n  if (text.length <= maxSize) {\n    return [text];\n  }\n\n  const chunks: string[] = [];\n  let start = 0;\n\n  while (start < text.length) {\n    let end = start + maxSize;\n    \n    if (end >= text.length) {\n      chunks.push(text.slice(start));\n      break;\n    }\n\n    // Try to break at word boundary\n    const breakPoint = findBreakPoint(text, start, end);\n    chunks.push(text.slice(start, breakPoint));\n    \n    start = Math.max(start + 1, breakPoint - overlap);\n  }\n\n  return chunks;\n}\n\nfunction findBreakPoint(text: string, start: number, end: number): number {\n  // Look for sentence boundary first\n  for (let i = end - 1; i > start + (end - start) * 0.7; i--) {\n    if (text[i] === '.' && text[i + 1] === ' ') {\n      return i + 1;\n    }\n  }\n  \n  // Fall back to word boundary\n  for (let i = end - 1; i > start + (end - start) * 0.5; i--) {\n    if (text[i] === ' ') {\n      return i;\n    }\n  }\n  \n  return end;\n}\n\nfunction createChunk(text: string, source: IngestSource, chunkIndex: number): Chunk {\n  const hash = createHash('sha256').update(text).digest('hex').slice(0, 16);\n  \n  return {\n    id: `${source.title}-${chunkIndex}-${hash}`,\n    text,\n    index: chunkIndex,\n    hash,\n    source: {\n      title: source.title,\n      ...(source.kind && { kind: source.kind }),\n    },\n    metadata: {},\n  };\n}\n\nfunction deduplicateChunks(chunks: Chunk[]): Chunk[] {\n  const seen = new Set<string>();\n  return chunks.filter(chunk => {\n    if (seen.has(chunk.hash)) {\n      return false;\n    }\n    seen.add(chunk.hash);\n    return true;\n  });\n}","import type { Chunk, QueryResult } from './types.js';\n\n/**\n * Utility functions for common Orquel operations\n * \n * These utilities help prevent common mistakes and reduce boilerplate code\n * when working with Orquel data structures.\n * \n * @example\n * ```typescript\n * import { OrquelUtils } from '@orquel/core';\n * \n * // Get chunk title safely\n * const title = OrquelUtils.getChunkTitle(chunk);\n * \n * // Format search results for display\n * const formatted = OrquelUtils.formatSearchResults(results);\n * console.log(formatted);\n * ```\n */\nexport class OrquelUtils {\n  /**\n   * Safely extract the title from a chunk's metadata\n   * \n   * @example\n   * ```typescript\n   * const chunk: Chunk = { id: 'test', text: 'content', metadata: { source: { title: 'Test' }, chunkIndex: 0, hash: 'abc' } };\n   * const title = OrquelUtils.getChunkTitle(chunk);\n   * console.log(title); // \"Document Title\" or \"Unknown Document\"\n   * ```\n   * \n   * @param chunk - The chunk to extract the title from\n   * @returns The title string, or \"Unknown Document\" if not available\n   */\n  static getChunkTitle(chunk: Chunk): string {\n    const title = chunk.metadata?.source?.title;\n    if (!title) {\n      console.warn('Warning: Chunk missing source title, using fallback');\n      return 'Unknown Document';\n    }\n    return title;\n  }\n\n  /**\n   * Extract unique source titles from an array of chunks\n   * \n   * @example\n   * ```typescript\n   * const contexts: Chunk[] = []; // Array of chunks\n   * const sources = OrquelUtils.getUniqueSourceTitles(contexts);\n   * sources.forEach(source => console.log(`â€¢ ${source}`));\n   * ```\n   * \n   * @param chunks - Array of chunks to extract titles from\n   * @returns Array of unique source titles (excluding undefined/null)\n   */\n  static getUniqueSourceTitles(chunks: Chunk[]): string[] {\n    const titles = chunks\n      .map(chunk => chunk.metadata?.source?.title)\n      .filter((title): title is string => Boolean(title));\n    \n    return [...new Set(titles)];\n  }\n\n  /**\n   * Format search results for display with titles and scores\n   * \n   * @example\n   * ```typescript\n   * const { results } = await orq.query(\"What is Argentina?\");\n   * const formatted = OrquelUtils.formatSearchResults(results);\n   * console.log(formatted);\n   * // Output:\n   * // 1. Geography of Argentina (0.847)\n   * // 2. History of Argentina (0.782)\n   * // 3. Culture of Argentina (0.756)\n   * ```\n   * \n   * @param results - Array of query results to format\n   * @returns Formatted string with numbered results, titles, and scores\n   */\n  static formatSearchResults(results: QueryResult[]): string {\n    if (results.length === 0) {\n      return 'No results found';\n    }\n\n    return results.map((result, index) => {\n      const title = this.getChunkTitle(result.chunk);\n      const score = result.score.toFixed(3);\n      return `${index + 1}. ${title} (${score})`;\n    }).join('\\n');\n  }\n\n  /**\n   * Validate chunk structure and provide helpful error messages\n   * \n   * @example\n   * ```typescript\n   * try {\n   *   OrquelUtils.validateChunk(chunk);\n   *   console.log(\"Chunk is valid!\");\n   * } catch (error) {\n   *   console.error(\"Chunk validation failed:\", error.message);\n   * }\n   * ```\n   * \n   * @param chunk - The chunk to validate\n   * @throws Error if chunk structure is invalid\n   */\n  static validateChunk(chunk: unknown): asserts chunk is Chunk {\n    if (!chunk || typeof chunk !== 'object') {\n      throw new Error('Chunk must be an object');\n    }\n\n    const c = chunk as any;\n\n    if (typeof c.id !== 'string') {\n      throw new Error('Chunk must have a string id');\n    }\n\n    if (typeof c.text !== 'string') {\n      throw new Error('Chunk must have a string text property');\n    }\n\n    if (!c.metadata || typeof c.metadata !== 'object') {\n      throw new Error('Chunk must have a metadata object');\n    }\n\n    if (!c.metadata.source || typeof c.metadata.source !== 'object') {\n      throw new Error('Chunk metadata must have a source object');\n    }\n\n    if (typeof c.metadata.source.title !== 'string') {\n      throw new Error('Chunk metadata.source must have a string title');\n    }\n  }\n\n  /**\n   * Inspect chunk structure for debugging purposes\n   * \n   * @example\n   * ```typescript\n   * OrquelUtils.inspectChunk(chunk);\n   * // Console output:\n   * // ðŸ” Chunk inspection:\n   * // â€¢ ID: chunk_123\n   * // â€¢ Text length: 542 characters\n   * // â€¢ Source: \"Geography of Argentina\"\n   * // â€¢ Chunk index: 3\n   * ```\n   * \n   * @param chunk - The chunk to inspect\n   */\n  static inspectChunk(chunk: Chunk): void {\n    console.log('ðŸ” Chunk inspection:');\n    console.log(`â€¢ ID: ${chunk.id}`);\n    console.log(`â€¢ Text length: ${chunk.text.length} characters`);\n    console.log(`â€¢ Source: \"${this.getChunkTitle(chunk)}\"`);\n    console.log(`â€¢ Chunk index: ${chunk.metadata?.chunkIndex ?? 'unknown'}`);\n    console.log(`â€¢ Has hash: ${chunk.metadata?.hash ? 'yes' : 'no'}`);\n    \n    if (chunk.text.length > 100) {\n      console.log(`â€¢ Text preview: \"${chunk.text.substring(0, 100)}...\"`);\n    } else {\n      console.log(`â€¢ Full text: \"${chunk.text}\"`);\n    }\n  }\n\n  /**\n   * Inspect query results structure for debugging\n   * \n   * @example\n   * ```typescript\n   * const { results } = await orq.query(\"What is Argentina?\");\n   * OrquelUtils.inspectQueryResults(results);\n   * ```\n   * \n   * @param results - The query results to inspect\n   */\n  static inspectQueryResults(results: QueryResult[]): void {\n    console.log('ðŸ“Š Query results inspection:');\n    console.log(`â€¢ Result count: ${results.length}`);\n    \n    if (results.length > 0) {\n      console.log(`â€¢ Score range: ${results[results.length - 1]!.score.toFixed(3)} - ${results[0]!.score.toFixed(3)}`);\n      console.log('â€¢ Sources found:');\n      \n      const sources = this.getUniqueSourceTitles(results.map(r => r.chunk));\n      sources.forEach(source => console.log(`  - ${source}`));\n      \n      console.log('â€¢ Sample result:');\n      this.inspectChunk(results[0]!.chunk);\n    }\n  }\n\n  /**\n   * Create a summary of contexts used in answer generation\n   * \n   * @example\n   * ```typescript\n   * const { contexts } = await orq.answer(\"What is Argentina?\");\n   * const summary = OrquelUtils.summarizeContexts(contexts);\n   * console.log(summary);\n   * // \"Based on 3 chunks from 2 sources: Geography of Argentina, Culture of Argentina\"\n   * ```\n   * \n   * @param contexts - Array of chunks used as context\n   * @returns Human-readable summary string\n   */\n  static summarizeContexts(contexts: Chunk[]): string {\n    const sources = this.getUniqueSourceTitles(contexts);\n    const chunkCount = contexts.length;\n    const sourceCount = sources.length;\n    \n    if (chunkCount === 0) {\n      return 'No contexts used';\n    }\n\n    const sourceList = sources.join(', ');\n    return `Based on ${chunkCount} chunk${chunkCount === 1 ? '' : 's'} from ${sourceCount} source${sourceCount === 1 ? '' : 's'}: ${sourceList}`;\n  }\n}","import type { SearchResult, HybridSearchOptions } from './types.js';\n\n/**\n * Reciprocal Rank Fusion (RRF) algorithm for combining search results\n * \n * RRF is particularly effective for hybrid search as it:\n * - Doesn't require score calibration between different search systems\n * - Is robust to score distribution differences\n * - Performs well across different domains\n * \n * Formula: RRF(d) = Î£(1 / (k + rank(d)))\n * where k is a constant (typically 60) and rank(d) is the rank of document d in each ranking\n */\nexport function reciprocalRankFusion(\n  denseResults: SearchResult[],\n  lexicalResults: SearchResult[],\n  k: number = 10,\n  rffConstant: number = 60\n): SearchResult[] {\n  // Create maps for efficient rank lookup\n  const denseRanks = new Map<string, number>();\n  const lexicalRanks = new Map<string, number>();\n  \n  // Build rank maps\n  denseResults.forEach((result, index) => {\n    denseRanks.set(result.chunk.id, index + 1); // 1-indexed ranks\n  });\n  \n  lexicalResults.forEach((result, index) => {\n    lexicalRanks.set(result.chunk.id, index + 1); // 1-indexed ranks\n  });\n  \n  // Collect all unique chunks\n  const allChunkIds = new Set([\n    ...denseResults.map(r => r.chunk.id),\n    ...lexicalResults.map(r => r.chunk.id),\n  ]);\n  \n  // Calculate RRF scores\n  const rrfResults: Array<{ id: string; score: number; chunk: SearchResult['chunk']; rank: number }> = [];\n  \n  for (const chunkId of allChunkIds) {\n    let rrfScore = 0;\n    let chunk: SearchResult['chunk'] | null = null;\n    \n    // Add contribution from dense results\n    const denseRank = denseRanks.get(chunkId);\n    if (denseRank !== undefined) {\n      rrfScore += 1 / (rffConstant + denseRank);\n      chunk = denseResults.find(r => r.chunk.id === chunkId)?.chunk || null;\n    }\n    \n    // Add contribution from lexical results\n    const lexicalRank = lexicalRanks.get(chunkId);\n    if (lexicalRank !== undefined) {\n      rrfScore += 1 / (rffConstant + lexicalRank);\n      if (!chunk) {\n        chunk = lexicalResults.find(r => r.chunk.id === chunkId)?.chunk || null;\n      }\n    }\n    \n    if (chunk) {\n      rrfResults.push({ id: chunkId, score: rrfScore, chunk, rank: 0 });\n    }\n  }\n  \n  // Sort by RRF score (descending) and assign final ranks\n  rrfResults.sort((a, b) => b.score - a.score);\n  \n  return rrfResults.slice(0, k).map((result, index) => ({\n    chunk: result.chunk,\n    score: result.score,\n    rank: index + 1,\n  }));\n}\n\n/**\n * Weighted score combination for hybrid search\n * Normalizes scores and combines them with configurable weights\n */\nexport function weightedScoreCombination(\n  denseResults: SearchResult[],\n  lexicalResults: SearchResult[],\n  k: number = 10,\n  denseWeight: number = 0.7,\n  lexicalWeight: number = 0.3\n): SearchResult[] {\n  // Normalize scores to [0, 1]\n  const normalizedDense = normalizeScores(denseResults);\n  const normalizedLexical = normalizeScores(lexicalResults);\n\n  // Create a map of chunk ID to combined result\n  const scoreMap = new Map<string, SearchResult>();\n\n  // Add dense results\n  for (const result of normalizedDense) {\n    scoreMap.set(result.chunk.id, {\n      ...result,\n      score: result.score * denseWeight,\n    });\n  }\n\n  // Add/merge lexical results\n  for (const result of normalizedLexical) {\n    const existing = scoreMap.get(result.chunk.id);\n    if (existing) {\n      existing.score += result.score * lexicalWeight;\n    } else {\n      scoreMap.set(result.chunk.id, {\n        ...result,\n        score: result.score * lexicalWeight,\n      });\n    }\n  }\n\n  // Sort by combined score and take top k\n  const sortedResults = Array.from(scoreMap.values())\n    .sort((a, b) => b.score - a.score)\n    .slice(0, k);\n\n  // Update ranks\n  return sortedResults.map((result, index) => ({\n    ...result,\n    rank: index + 1,\n  }));\n}\n\n/**\n * Min-Max normalization: scales scores to [0, 1] range\n */\nfunction normalizeScoresMinMax(results: SearchResult[]): SearchResult[] {\n  if (results.length === 0) return results;\n\n  const scores = results.map(r => r.score);\n  const min = Math.min(...scores);\n  const max = Math.max(...scores);\n  \n  // Handle edge case where all scores are the same\n  if (max === min) {\n    return results.map(result => ({ ...result, score: 1 }));\n  }\n\n  return results.map(result => ({\n    ...result,\n    score: (result.score - min) / (max - min),\n  }));\n}\n\n/**\n * Z-score normalization: normalizes to zero mean and unit variance\n */\nfunction normalizeScoresZScore(results: SearchResult[]): SearchResult[] {\n  if (results.length === 0) return results;\n  if (results.length === 1) return results.map(r => ({ ...r, score: 1 }));\n\n  const scores = results.map(r => r.score);\n  const mean = scores.reduce((sum, score) => sum + score, 0) / scores.length;\n  const variance = scores.reduce((sum, score) => sum + Math.pow(score - mean, 2), 0) / scores.length;\n  const stdDev = Math.sqrt(variance);\n  \n  // Handle edge case where standard deviation is 0\n  if (stdDev === 0) {\n    return results.map(result => ({ ...result, score: 1 }));\n  }\n\n  // Convert z-scores to [0, 1] range using sigmoid function\n  return results.map(result => {\n    const zScore = (result.score - mean) / stdDev;\n    const normalizedScore = 1 / (1 + Math.exp(-zScore)); // Sigmoid function\n    return { ...result, score: normalizedScore };\n  });\n}\n\n/**\n * Normalize scores using the specified method\n */\nexport function normalizeScores(\n  results: SearchResult[],\n  method: 'minmax' | 'zscore' = 'minmax'\n): SearchResult[] {\n  switch (method) {\n    case 'minmax':\n      return normalizeScoresMinMax(results);\n    case 'zscore':\n      return normalizeScoresZScore(results);\n    default:\n      return normalizeScoresMinMax(results);\n  }\n}\n\n/**\n * Merge hybrid search results using the specified algorithm\n */\nexport function mergeHybridResults(\n  denseResults: SearchResult[],\n  lexicalResults: SearchResult[],\n  options: HybridSearchOptions & { k: number }\n): SearchResult[] {\n  const {\n    k = 10,\n    denseWeight = 0.7,\n    lexicalWeight = 0.3,\n    normalizationMethod = 'rrf',\n  } = options;\n\n  switch (normalizationMethod) {\n    case 'rrf':\n      return reciprocalRankFusion(denseResults, lexicalResults, k);\n    case 'minmax':\n    case 'zscore':\n      return weightedScoreCombination(\n        denseResults,\n        lexicalResults,\n        k,\n        denseWeight,\n        lexicalWeight\n      );\n    default:\n      return reciprocalRankFusion(denseResults, lexicalResults, k);\n  }\n}\n\n/**\n * Analyze the overlap between dense and lexical results\n * Useful for understanding search performance and tuning weights\n */\nexport function analyzeHybridOverlap(\n  denseResults: SearchResult[],\n  lexicalResults: SearchResult[]\n): {\n  denseOnlyCount: number;\n  lexicalOnlyCount: number;\n  overlapCount: number;\n  overlapPercentage: number;\n  complementaryScore: number; // How well the methods complement each other\n} {\n  const denseIds = new Set(denseResults.map(r => r.chunk.id));\n  const lexicalIds = new Set(lexicalResults.map(r => r.chunk.id));\n  \n  const overlapIds = new Set([...denseIds].filter(id => lexicalIds.has(id)));\n  \n  const denseOnlyCount = denseIds.size - overlapIds.size;\n  const lexicalOnlyCount = lexicalIds.size - overlapIds.size;\n  const overlapCount = overlapIds.size;\n  \n  const totalUnique = denseIds.size + lexicalIds.size - overlapIds.size;\n  const overlapPercentage = totalUnique > 0 ? (overlapCount / totalUnique) * 100 : 0;\n  \n  // Complementary score: higher when methods find different relevant results\n  // Range: 0 (complete overlap) to 1 (no overlap)\n  const complementaryScore = totalUnique > 0 ? (denseOnlyCount + lexicalOnlyCount) / totalUnique : 0;\n  \n  return {\n    denseOnlyCount,\n    lexicalOnlyCount,\n    overlapCount,\n    overlapPercentage,\n    complementaryScore,\n  };\n}","import type {\n  Orquel,\n  OrquelConfig,\n  IngestArgs,\n  QueryOptions,\n  AnswerOptions,\n  Chunk,\n  SearchResult,\n} from './types.js';\nimport { defaultChunker } from './chunker.js';\nimport { OrquelUtils } from './utils.js';\nimport { mergeHybridResults, analyzeHybridOverlap } from './hybrid.js';\n\n/**\n * Create a new Orquel instance with the specified configuration\n * \n * @param config - Configuration object specifying adapters and options\n * @returns Configured Orquel instance\n * \n * @example\n * ```typescript\n * import { createOrquel } from '@orquel/core';\n * import { openAIEmbeddings } from '@orquel/embeddings-openai';\n * import { memoryStore } from '@orquel/store-memory';\n * \n * const orq = createOrquel({\n *   embeddings: openAIEmbeddings(),\n *   vector: memoryStore(),\n *   debug: true  // Enable debugging features\n * });\n * ```\n */\nexport function createOrquel(config: OrquelConfig): Orquel {\n  const chunker = config.chunker || ((text: string) => \n    defaultChunker(text, { title: 'Unknown' })\n  );\n  const debug = config.debug ?? false;\n\n  if (debug) {\n    console.log('ðŸ› Orquel Debug Mode Enabled');\n    console.log('ðŸ“‹ Configuration:');\n    console.log(`  â€¢ Embeddings: ${config.embeddings.name}`);\n    console.log(`  â€¢ Vector Store: ${config.vector.name}`);\n    console.log(`  â€¢ Lexical: ${config.lexical?.name || 'none'}`);\n    console.log(`  â€¢ Reranker: ${config.reranker?.name || 'none'}`);\n    console.log(`  â€¢ Answerer: ${config.answerer?.name || 'none'}`);\n  }\n\n  return {\n    async ingest(args: IngestArgs) {\n      if (debug) {\n        console.log(`ðŸ”„ Ingesting: \"${args.source.title}\"`);\n        console.log(`ðŸ“ Content length: ${typeof args.content === 'string' ? args.content.length : args.content.byteLength} ${typeof args.content === 'string' ? 'characters' : 'bytes'}`);\n      }\n\n      const content = typeof args.content === 'string' \n        ? args.content \n        : args.content.toString('utf-8');\n      \n      const chunks = chunker(content);\n      \n      if (debug) {\n        console.log(`âœ‚ï¸  Chunked into ${chunks.length} pieces`);\n        if (chunks.length > 0) {\n          console.log(`ðŸ“ Chunk size range: ${Math.min(...chunks.map(c => c.text.length))}-${Math.max(...chunks.map(c => c.text.length))} characters`);\n        }\n      }\n      \n      // Update chunks with proper source info\n      const updatedChunks = chunks.map(chunk => ({\n        ...chunk,\n        metadata: {\n          ...chunk.metadata,\n          source: args.source,\n        },\n      }));\n\n      // Validate chunks in debug mode\n      if (debug && updatedChunks.length > 0) {\n        try {\n          OrquelUtils.validateChunk(updatedChunks[0]);\n          console.log('âœ… Chunk structure validation passed');\n        } catch (error) {\n          console.warn('âš ï¸  Chunk validation warning:', error);\n        }\n      }\n\n      return {\n        sourceId: args.source.title,\n        chunks: updatedChunks,\n      };\n    },\n\n    async index(chunks: Chunk[]) {\n      if (debug) {\n        console.log(`ðŸ“š Indexing ${chunks.length} chunks...`);\n      }\n\n      // Embed all chunks\n      const texts = chunks.map(chunk => chunk.text);\n      const embeddings = await config.embeddings.embed(texts);\n      \n      if (debug) {\n        console.log(`ðŸ§  Generated ${embeddings.length} embeddings (${config.embeddings.dim}D)`);\n      }\n      \n      // Prepare rows for vector store\n      const rows = chunks.map((chunk, i) => ({\n        chunk,\n        embedding: embeddings[i]!,\n      }));\n\n      // Index in vector store\n      await config.vector.upsert(rows);\n\n      // Index in lexical store if available\n      if (config.lexical) {\n        await config.lexical.index(chunks);\n        if (debug) {\n          console.log(`ðŸ”¤ Indexed in lexical store: ${config.lexical.name}`);\n        }\n      }\n\n      if (debug) {\n        console.log('âœ… Indexing completed');\n      }\n    },\n\n    async query(q: string, opts: QueryOptions = {}) {\n      if (debug) {\n        console.log(`ðŸ” Querying: \"${q}\"`);\n        console.log(`âš™ï¸  Options: k=${opts.k || 10}, hybrid=${opts.hybrid ?? !!config.lexical}, rerank=${opts.rerank ?? !!config.reranker}`);\n      }\n\n      const { k = 10, hybrid = !!config.lexical, rerank = !!config.reranker } = opts;\n      \n      let results: SearchResult[] = [];\n\n      if (hybrid && config.lexical) {\n        if (debug) {\n          console.log('ðŸ”„ Using hybrid search (dense + lexical)');\n        }\n        // Hybrid search: combine dense and lexical\n        const [queryEmbedding] = await config.embeddings.embed([q]);\n        const denseResults = await config.vector.searchByVector(queryEmbedding!, k);\n        const lexicalResults = await config.lexical.search(q, k);\n        \n        if (debug) {\n          console.log(`ðŸ“Š Dense results: ${denseResults.length}, Lexical results: ${lexicalResults.length}`);\n        }\n        \n        // Analyze overlap if debug mode is enabled\n        if (debug) {\n          const overlap = analyzeHybridOverlap(denseResults, lexicalResults);\n          console.log(`ðŸ”„ Search overlap: ${overlap.overlapCount} shared, ${overlap.denseOnlyCount} dense-only, ${overlap.lexicalOnlyCount} lexical-only`);\n          console.log(`ðŸ“Š Complementary score: ${(overlap.complementaryScore * 100).toFixed(1)}%`);\n        }\n        \n        // Merge results using configured hybrid options\n        const hybridOptions = config.hybrid || {};\n        results = mergeHybridResults(denseResults, lexicalResults, { ...hybridOptions, k });\n      } else {\n        if (debug) {\n          console.log('ðŸ”„ Using dense-only search');\n        }\n        // Dense-only search\n        const [queryEmbedding] = await config.embeddings.embed([q]);\n        results = await config.vector.searchByVector(queryEmbedding!, k);\n      }\n\n      // Apply reranking if available\n      if (rerank && config.reranker && results.length > 0) {\n        if (debug) {\n          console.log(`ðŸŽ¯ Applying reranking with ${config.reranker.name}`);\n        }\n        const chunks = results.map(r => r.chunk);\n        const rerankedIndices = await config.reranker.rerank(q, chunks);\n        results = rerankedIndices.map(idx => results[idx]!);\n      }\n\n      if (debug) {\n        console.log(`ðŸ“‹ Final results: ${results.length}`);\n        if (results.length > 0) {\n          OrquelUtils.inspectQueryResults(results);\n        }\n      }\n\n      return { results };\n    },\n\n    async answer(q: string, opts: AnswerOptions = {}) {\n      if (debug) {\n        console.log(`ðŸ’¬ Generating answer for: \"${q}\"`);\n        console.log(`âš™ï¸  Options: topK=${opts.topK || 4}`);\n      }\n\n      const { topK = 4 } = opts;\n      \n      if (!config.answerer) {\n        throw new Error('No answerer configured');\n      }\n\n      // Get relevant contexts\n      const { results } = await this.query(q, { k: topK });\n      const contexts = results.map(r => r.chunk);\n\n      if (debug) {\n        console.log(`ðŸ“š Using ${contexts.length} contexts for answer generation`);\n        console.log(`ðŸ¤– Generating answer with ${config.answerer.name}...`);\n        console.log('ðŸ“ Context summary:', OrquelUtils.summarizeContexts(contexts));\n      }\n\n      // Generate answer\n      const answer = await config.answerer.answer({\n        query: q,\n        contexts,\n      });\n\n      if (debug) {\n        console.log(`âœ… Answer generated (${answer.length} characters)`);\n        if (answer.length > 150) {\n          console.log(`ðŸ“– Answer preview: \"${answer.substring(0, 150)}...\"`);\n        } else {\n          console.log(`ðŸ“– Full answer: \"${answer}\"`);\n        }\n      }\n\n      return { answer, contexts };\n    },\n  };\n}\n\n","import type { Orquel, Chunk, QueryResult } from './types.js';\n\n/**\n * Evaluation metrics for RAG system performance\n */\nexport interface EvaluationMetrics {\n  /** Precision: How many retrieved chunks are relevant */\n  precision: number;\n  /** Recall: How many relevant chunks were retrieved */\n  recall: number;\n  /** F1 Score: Harmonic mean of precision and recall */\n  f1Score: number;\n  /** Mean Reciprocal Rank: Average of reciprocal ranks of first relevant result */\n  mrr: number;\n  /** Normalized Discounted Cumulative Gain: Quality of ranking */\n  ndcg: number;\n  /** Hit Rate: Percentage of queries with at least one relevant result */\n  hitRate: number;\n  /** Average response time in milliseconds */\n  avgResponseTime: number;\n}\n\n/**\n * A ground truth query with expected relevant chunks\n */\nexport interface GroundTruthQuery {\n  /** The query text */\n  query: string;\n  /** IDs of chunks that should be considered relevant */\n  relevantChunkIds: string[];\n  /** Optional: Expected answer text for answer evaluation */\n  expectedAnswer?: string;\n  /** Optional: Keywords that should appear in the answer */\n  expectedKeywords?: string[];\n}\n\n/**\n * Results from evaluating a single query\n */\nexport interface QueryEvaluationResult {\n  query: string;\n  retrievedChunkIds: string[];\n  relevantChunkIds: string[];\n  precision: number;\n  recall: number;\n  f1Score: number;\n  reciprocalRank: number;\n  dcg: number;\n  ndcg: number;\n  hasRelevantResult: boolean;\n  responseTime: number;\n  answer?: string;\n  answerScore?: number;\n}\n\n/**\n * Configuration for evaluation runs\n */\nexport interface EvaluationConfig {\n  /** Number of results to retrieve for each query (k parameter) */\n  k?: number;\n  /** Whether to use hybrid search */\n  hybrid?: boolean;\n  /** Whether to use reranking */\n  rerank?: boolean;\n  /** Whether to evaluate answer generation */\n  evaluateAnswers?: boolean;\n  /** Custom relevance scoring function */\n  relevanceScorer?: (query: string, chunk: Chunk) => number;\n}\n\n/**\n * Comprehensive evaluation harness for RAG systems\n */\nexport class RAGEvaluator {\n  private orquel: Orquel;\n\n  constructor(orquel: Orquel) {\n    this.orquel = orquel;\n  }\n\n  /**\n   * Evaluate the RAG system against ground truth queries\n   * \n   * @example\n   * ```typescript\n   * const evaluator = new RAGEvaluator(orq);\n   * \n   * const groundTruth = [\n   *   {\n   *     query: \"What is the capital of Argentina?\",\n   *     relevantChunkIds: [\"argentina-geography-1\", \"argentina-cities-2\"],\n   *     expectedAnswer: \"Buenos Aires\",\n   *     expectedKeywords: [\"Buenos Aires\", \"capital\"]\n   *   }\n   * ];\n   * \n   * const metrics = await evaluator.evaluate(groundTruth);\n   * console.log(`F1 Score: ${metrics.f1Score.toFixed(3)}`);\n   * ```\n   */\n  async evaluate(\n    groundTruthQueries: GroundTruthQuery[],\n    config: EvaluationConfig = {}\n  ): Promise<EvaluationMetrics> {\n    const {\n      k = 10,\n      hybrid = false,\n      rerank = false,\n      evaluateAnswers = false,\n    } = config;\n\n    const queryResults: QueryEvaluationResult[] = [];\n    let totalResponseTime = 0;\n\n    for (const groundTruth of groundTruthQueries) {\n      const startTime = Date.now();\n\n      try {\n        // Perform retrieval\n        const { results } = await this.orquel.query(groundTruth.query, {\n          k,\n          hybrid,\n          rerank,\n        });\n\n        const responseTime = Date.now() - startTime;\n        totalResponseTime += responseTime;\n\n        // Evaluate retrieval performance\n        const retrievedChunkIds = results.map(r => r.chunk.id);\n        const evaluation = this.evaluateQuery(\n          groundTruth.query,\n          retrievedChunkIds,\n          groundTruth.relevantChunkIds,\n          results\n        );\n\n        // Evaluate answer generation if requested\n        let answer: string | undefined;\n        let answerScore: number | undefined;\n\n        if (evaluateAnswers && groundTruth.expectedAnswer) {\n          try {\n            const answerResult = await this.orquel.answer(groundTruth.query);\n            answer = answerResult.answer;\n            answerScore = this.evaluateAnswer(\n              answer,\n              groundTruth.expectedAnswer,\n              groundTruth.expectedKeywords\n            );\n          } catch (answerError) {\n            console.warn(`Answer generation failed for query \"${groundTruth.query}\":`, answerError);\n            // Continue with undefined answer/answerScore\n          }\n        }\n\n        const result: QueryEvaluationResult = {\n          ...evaluation,\n          responseTime,\n        };\n        \n        if (answer !== undefined) {\n          result.answer = answer;\n        }\n        if (answerScore !== undefined) {\n          result.answerScore = answerScore;\n        }\n        \n        queryResults.push(result);\n      } catch (error) {\n        console.warn(`Failed to evaluate query \"${groundTruth.query}\":`, error);\n        \n        // Record failed query with zero scores\n        queryResults.push({\n          query: groundTruth.query,\n          retrievedChunkIds: [],\n          relevantChunkIds: groundTruth.relevantChunkIds,\n          precision: 0,\n          recall: 0,\n          f1Score: 0,\n          reciprocalRank: 0,\n          dcg: 0,\n          ndcg: 0,\n          hasRelevantResult: false,\n          responseTime: Date.now() - startTime,\n        });\n      }\n    }\n\n    return this.aggregateMetrics(queryResults, totalResponseTime);\n  }\n\n  /**\n   * Evaluate a single query against ground truth\n   */\n  private evaluateQuery(\n    query: string,\n    retrievedChunkIds: string[],\n    relevantChunkIds: string[],\n    results: QueryResult[]\n  ): QueryEvaluationResult {\n    const relevantSet = new Set(relevantChunkIds);\n    const retrievedRelevant = retrievedChunkIds.filter(id => relevantSet.has(id));\n\n    // Calculate precision and recall\n    const precision = retrievedChunkIds.length > 0 \n      ? retrievedRelevant.length / retrievedChunkIds.length \n      : 0;\n    \n    const recall = relevantChunkIds.length > 0 \n      ? retrievedRelevant.length / relevantChunkIds.length \n      : 0;\n\n    // Calculate F1 score\n    const f1Score = precision + recall > 0 \n      ? (2 * precision * recall) / (precision + recall) \n      : 0;\n\n    // Calculate reciprocal rank (MRR)\n    let reciprocalRank = 0;\n    for (let i = 0; i < retrievedChunkIds.length; i++) {\n      if (relevantSet.has(retrievedChunkIds[i]!)) {\n        reciprocalRank = 1 / (i + 1);\n        break;\n      }\n    }\n\n    // Calculate NDCG\n    const { dcg, ndcg } = this.calculateNDCG(retrievedChunkIds, relevantChunkIds);\n\n    const hasRelevantResult = retrievedRelevant.length > 0;\n\n    return {\n      query,\n      retrievedChunkIds,\n      relevantChunkIds,\n      precision,\n      recall,\n      f1Score,\n      reciprocalRank,\n      dcg,\n      ndcg,\n      hasRelevantResult,\n      responseTime: 0, // Will be set by caller\n    };\n  }\n\n  /**\n   * Calculate Discounted Cumulative Gain and Normalized DCG\n   */\n  private calculateNDCG(\n    retrievedChunkIds: string[],\n    relevantChunkIds: string[]\n  ): { dcg: number; ndcg: number } {\n    const relevantSet = new Set(relevantChunkIds);\n\n    // Calculate DCG\n    let dcg = 0;\n    for (let i = 0; i < retrievedChunkIds.length; i++) {\n      const relevance = relevantSet.has(retrievedChunkIds[i]!) ? 1 : 0;\n      dcg += relevance / Math.log2(i + 2); // i+2 because log2(1) = 0\n    }\n\n    // Calculate ideal DCG (IDCG)\n    let idcg = 0;\n    for (let i = 0; i < Math.min(relevantChunkIds.length, retrievedChunkIds.length); i++) {\n      idcg += 1 / Math.log2(i + 2);\n    }\n\n    const ndcg = idcg > 0 ? dcg / idcg : 0;\n\n    return { dcg, ndcg };\n  }\n\n  /**\n   * Evaluate answer quality against expected answer\n   */\n  private evaluateAnswer(\n    actualAnswer: string | undefined,\n    expectedAnswer: string,\n    expectedKeywords?: string[]\n  ): number {\n    if (!actualAnswer) {\n      return 0;\n    }\n    \n    let score = 0;\n    const actualLower = actualAnswer.toLowerCase();\n    const expectedLower = expectedAnswer.toLowerCase();\n\n    // Basic similarity score (simple word overlap)\n    const actualWords = new Set(actualLower.split(/\\s+/));\n    const expectedWords = new Set(expectedLower.split(/\\s+/));\n    const intersection = new Set([...actualWords].filter(w => expectedWords.has(w)));\n    const union = new Set([...actualWords, ...expectedWords]);\n    \n    if (union.size > 0) {\n      score += (intersection.size / union.size) * 0.5; // 50% weight for word overlap\n    }\n\n    // Check for expected keywords\n    if (expectedKeywords) {\n      let keywordScore = 0;\n      for (const keyword of expectedKeywords) {\n        if (actualLower.includes(keyword.toLowerCase())) {\n          keywordScore++;\n        }\n      }\n      score += (keywordScore / expectedKeywords.length) * 0.5; // 50% weight for keywords\n    }\n\n    return Math.min(score, 1.0); // Cap at 1.0\n  }\n\n  /**\n   * Aggregate individual query results into overall metrics\n   */\n  private aggregateMetrics(\n    queryResults: QueryEvaluationResult[],\n    totalResponseTime: number\n  ): EvaluationMetrics {\n    if (queryResults.length === 0) {\n      return {\n        precision: 0,\n        recall: 0,\n        f1Score: 0,\n        mrr: 0,\n        ndcg: 0,\n        hitRate: 0,\n        avgResponseTime: 0,\n      };\n    }\n\n    const totalQueries = queryResults.length;\n\n    // Average metrics\n    const precision = queryResults.reduce((sum, r) => sum + r.precision, 0) / totalQueries;\n    const recall = queryResults.reduce((sum, r) => sum + r.recall, 0) / totalQueries;\n    const f1Score = queryResults.reduce((sum, r) => sum + r.f1Score, 0) / totalQueries;\n    const mrr = queryResults.reduce((sum, r) => sum + r.reciprocalRank, 0) / totalQueries;\n    const ndcg = queryResults.reduce((sum, r) => sum + r.ndcg, 0) / totalQueries;\n\n    // Hit rate (percentage of queries with at least one relevant result)\n    const hitRate = queryResults.filter(r => r.hasRelevantResult).length / totalQueries;\n\n    // Average response time\n    const avgResponseTime = totalResponseTime / totalQueries;\n\n    return {\n      precision,\n      recall,\n      f1Score,\n      mrr,\n      ndcg,\n      hitRate,\n      avgResponseTime,\n    };\n  }\n\n  /**\n   * Generate detailed evaluation report\n   */\n  async generateReport(\n    groundTruthQueries: GroundTruthQuery[],\n    config: EvaluationConfig = {}\n  ): Promise<string> {\n    const metrics = await this.evaluate(groundTruthQueries, config);\n    const { k = 10, hybrid = false, rerank = false } = config;\n\n    const report = `\n# RAG System Evaluation Report\n\n## Configuration\n- **Retrieval K**: ${k}\n- **Hybrid Search**: ${hybrid ? 'Enabled' : 'Disabled'}\n- **Reranking**: ${rerank ? 'Enabled' : 'Disabled'}\n- **Total Queries**: ${groundTruthQueries.length}\n\n## Overall Performance\n\n| Metric | Score | Description |\n|--------|-------|-------------|\n| **Precision** | ${metrics.precision.toFixed(3)} | Fraction of retrieved chunks that are relevant |\n| **Recall** | ${metrics.recall.toFixed(3)} | Fraction of relevant chunks that were retrieved |\n| **F1 Score** | ${metrics.f1Score.toFixed(3)} | Harmonic mean of precision and recall |\n| **MRR** | ${metrics.mrr.toFixed(3)} | Mean Reciprocal Rank of first relevant result |\n| **NDCG** | ${metrics.ndcg.toFixed(3)} | Normalized Discounted Cumulative Gain |\n| **Hit Rate** | ${(metrics.hitRate * 100).toFixed(1)}% | Percentage of queries with â‰¥1 relevant result |\n| **Avg Response Time** | ${metrics.avgResponseTime.toFixed(1)}ms | Average query response time |\n\n## Performance Interpretation\n\n### Quality Assessment\n${this.getPerformanceAssessment(metrics)}\n\n### Recommendations\n${this.getRecommendations(metrics)}\n\n## Benchmarking Context\n\nFor reference, typical RAG system performance ranges:\n- **Good**: Precision > 0.7, Recall > 0.6, F1 > 0.65\n- **Acceptable**: Precision > 0.5, Recall > 0.4, F1 > 0.45\n- **Needs Improvement**: F1 < 0.45\n\n---\n*Generated by Orquel RAG Evaluator*\n`.trim();\n\n    return report;\n  }\n\n  /**\n   * Get performance assessment based on metrics\n   */\n  private getPerformanceAssessment(metrics: EvaluationMetrics): string {\n    const { precision, recall, f1Score, hitRate } = metrics;\n\n    if (f1Score >= 0.7) {\n      return 'ðŸŸ¢ **Excellent**: Your RAG system is performing very well with high precision and recall.';\n    } else if (f1Score >= 0.55) {\n      return 'ðŸŸ¡ **Good**: Your RAG system shows solid performance with room for optimization.';\n    } else if (f1Score >= 0.4) {\n      return 'ðŸŸ  **Fair**: Your RAG system is functional but would benefit from improvements.';\n    } else {\n      return 'ðŸ”´ **Needs Improvement**: Your RAG system requires significant optimization.';\n    }\n  }\n\n  /**\n   * Get recommendations based on metrics\n   */\n  private getRecommendations(metrics: EvaluationMetrics): string {\n    const recommendations: string[] = [];\n    const { precision, recall, f1Score, hitRate, avgResponseTime } = metrics;\n\n    if (precision < 0.6) {\n      recommendations.push('â€¢ **Low Precision**: Consider improving chunk quality, using reranking, or refining embedding model');\n    }\n\n    if (recall < 0.5) {\n      recommendations.push('â€¢ **Low Recall**: Try increasing k parameter, using hybrid search, or improving chunking strategy');\n    }\n\n    if (hitRate < 0.8) {\n      recommendations.push('â€¢ **Low Hit Rate**: Consider expanding knowledge base coverage or improving query understanding');\n    }\n\n    if (avgResponseTime > 2000) {\n      recommendations.push('â€¢ **Slow Response**: Optimize vector search, consider caching, or use faster embedding models');\n    }\n\n    if (precision > 0.8 && recall < 0.5) {\n      recommendations.push('â€¢ **High Precision, Low Recall**: Increase retrieval breadth with higher k or hybrid search');\n    }\n\n    if (recall > 0.8 && precision < 0.5) {\n      recommendations.push('â€¢ **High Recall, Low Precision**: Add reranking or improve chunk relevance filtering');\n    }\n\n    return recommendations.length > 0 \n      ? recommendations.join('\\n')\n      : 'â€¢ Your system is well-balanced. Consider A/B testing different configurations for marginal gains.';\n  }\n}\n\n/**\n * Create a basic evaluation dataset for testing\n */\nexport function createSampleEvaluationDataset(): GroundTruthQuery[] {\n  return [\n    {\n      query: \"What is Argentina?\",\n      relevantChunkIds: [\"geography-argentina-1\", \"overview-argentina-1\"],\n      expectedAnswer: \"Argentina is a country in South America\",\n      expectedKeywords: [\"country\", \"South America\", \"Argentina\"]\n    },\n    {\n      query: \"What is the capital of Argentina?\",\n      relevantChunkIds: [\"cities-argentina-1\", \"buenos-aires-1\"],\n      expectedAnswer: \"Buenos Aires is the capital of Argentina\",\n      expectedKeywords: [\"Buenos Aires\", \"capital\"]\n    },\n    {\n      query: \"Tell me about Argentine culture\",\n      relevantChunkIds: [\"culture-argentina-1\", \"traditions-argentina-1\", \"arts-argentina-1\"],\n      expectedAnswer: \"Argentine culture is influenced by European immigration\",\n      expectedKeywords: [\"culture\", \"European\", \"traditions\"]\n    },\n    {\n      query: \"What foods are popular in Argentina?\",\n      relevantChunkIds: [\"food-argentina-1\", \"cuisine-argentina-1\", \"gastronomy-argentina-1\"],\n      expectedAnswer: \"Argentina is famous for beef, empanadas, and mate\",\n      expectedKeywords: [\"beef\", \"empanadas\", \"mate\", \"asado\"]\n    }\n  ];\n}","/**\n * Performance benchmarking utilities for Orquel\n * \n * This module provides comprehensive performance testing tools to:\n * - Measure adapter performance across different scales\n * - Compare memory store vs PostgreSQL performance\n * - Benchmark hybrid search algorithms\n * - Generate performance reports and recommendations\n */\n\nimport type { \n  VectorStoreAdapter, \n  LexicalAdapter, \n  EmbeddingsAdapter,\n  SearchResult, \n  ChunkWithEmbedding,\n  Chunk \n} from './types.js';\n\nexport interface BenchmarkConfig {\n  /** Number of chunks to test with */\n  chunkCounts: number[];\n  /** Vector dimensions for testing */\n  dimensions: number;\n  /** Number of search queries to run */\n  searchQueries: number;\n  /** k value for search results */\n  k: number;\n  /** Number of runs to average */\n  runs: number;\n  /** Warm-up runs before measurement */\n  warmupRuns?: number;\n}\n\nexport interface PerformanceMetrics {\n  /** Operation name */\n  operation: string;\n  /** Number of items processed */\n  itemCount: number;\n  /** Time in milliseconds */\n  duration: number;\n  /** Items per second */\n  throughput: number;\n  /** Memory usage in MB (if available) */\n  memoryMB?: number;\n  /** Additional metadata */\n  metadata?: Record<string, any>;\n}\n\nexport interface BenchmarkResult {\n  /** Adapter name being tested */\n  adapterName: string;\n  /** Test configuration used */\n  config: BenchmarkConfig;\n  /** Performance metrics for each operation */\n  metrics: PerformanceMetrics[];\n  /** Overall summary statistics */\n  summary: {\n    avgUpsertThroughput: number;\n    avgSearchLatency: number;\n    peakMemoryMB?: number;\n    recommendation: string;\n  };\n  /** Timestamp when benchmark was run */\n  timestamp: Date;\n}\n\nexport interface ComparisonResult {\n  /** Results being compared */\n  results: BenchmarkResult[];\n  /** Performance comparison analysis */\n  analysis: {\n    /** Which adapter performed best for each operation */\n    bestPerformers: Record<string, string>;\n    /** Performance ratios (how many times faster/slower) */\n    ratios: Record<string, Record<string, number>>;\n    /** Recommendations based on use case */\n    recommendations: {\n      development: string;\n      production: string;\n      largescale: string;\n    };\n  };\n}\n\n/**\n * Generate realistic test chunks for benchmarking\n */\nexport function generateTestChunks(count: number, dimensions: number): ChunkWithEmbedding[] {\n  const chunks: ChunkWithEmbedding[] = [];\n  \n  const sampleTexts = [\n    \"Machine learning algorithms process vast amounts of data to identify patterns and make predictions.\",\n    \"Database systems provide structured storage and efficient retrieval of information using SQL queries.\",\n    \"Web development frameworks simplify the creation of dynamic user interfaces and server-side applications.\",\n    \"Cloud computing platforms enable scalable deployment of applications with global availability and reliability.\",\n    \"Artificial intelligence research focuses on creating systems that can perform tasks requiring human-like intelligence.\",\n    \"Software architecture patterns help organize code for maintainability, scalability, and testability.\",\n    \"Data analysis techniques extract meaningful insights from raw information to support decision making.\",\n    \"Network protocols ensure reliable communication between distributed systems across the internet.\",\n    \"Security measures protect digital assets from unauthorized access and malicious attacks.\",\n    \"User experience design prioritizes intuitive interfaces that enhance user satisfaction and engagement.\"\n  ];\n  \n  for (let i = 0; i < count; i++) {\n    const textIndex = i % sampleTexts.length;\n    const baseText = sampleTexts[textIndex];\n    \n    chunks.push({\n      chunk: {\n        id: `benchmark-chunk-${i}`,\n        text: `${baseText} This is chunk number ${i} with unique content for testing purposes.`,\n        index: i,\n        hash: `hash-${i}`,\n        source: {\n          title: `Benchmark Document ${Math.floor(i / 10)}`,\n          kind: 'md',\n        },\n        metadata: {\n          benchmarkId: i,\n          category: ['ai', 'database', 'web', 'cloud', 'security'][i % 5],\n        },\n      },\n      embedding: generateRandomEmbedding(dimensions),\n    });\n  }\n  \n  return chunks;\n}\n\n/**\n * Generate random embedding vector for testing\n */\nfunction generateRandomEmbedding(dimensions: number): number[] {\n  return Array.from({ length: dimensions }, () => Math.random() * 2 - 1);\n}\n\n/**\n * Generate realistic search queries for benchmarking\n */\nexport function generateSearchQueries(count: number): { text: string; embedding: number[] }[] {\n  const queryTexts = [\n    \"machine learning algorithms\",\n    \"database query optimization\", \n    \"web application security\",\n    \"cloud computing scalability\",\n    \"artificial intelligence research\",\n    \"software architecture patterns\",\n    \"data analysis techniques\",\n    \"network communication protocols\",\n    \"user interface design\",\n    \"system performance monitoring\"\n  ];\n  \n  const queries: { text: string; embedding: number[] }[] = [];\n  \n  for (let i = 0; i < count; i++) {\n    const text = queryTexts[i % queryTexts.length] + ` query ${i}`;\n    queries.push({\n      text,\n      embedding: generateRandomEmbedding(1536), // Default to OpenAI dimensions\n    });\n  }\n  \n  return queries;\n}\n\n/**\n * Measure memory usage (Node.js specific)\n */\nfunction measureMemory(): number {\n  if (typeof process !== 'undefined' && process.memoryUsage) {\n    const usage = process.memoryUsage();\n    return usage.heapUsed / 1024 / 1024; // Convert to MB\n  }\n  return 0;\n}\n\n/**\n * Run performance benchmark on a vector store adapter\n */\nexport async function benchmarkVectorStore(\n  adapter: VectorStoreAdapter,\n  config: BenchmarkConfig\n): Promise<BenchmarkResult> {\n  const metrics: PerformanceMetrics[] = [];\n  const startMemory = measureMemory();\n  \n  console.log(`ðŸ”¬ Benchmarking ${adapter.name}...`);\n  \n  for (const chunkCount of config.chunkCounts) {\n    console.log(`  ðŸ“Š Testing with ${chunkCount} chunks...`);\n    \n    // Generate test data\n    const testChunks = generateTestChunks(chunkCount, config.dimensions);\n    const queries = generateSearchQueries(config.searchQueries);\n    \n    // Warm-up runs\n    if (config.warmupRuns && config.warmupRuns > 0) {\n      const warmupChunks = generateTestChunks(Math.min(100, chunkCount), config.dimensions);\n      for (let i = 0; i < config.warmupRuns; i++) {\n        await adapter.upsert(warmupChunks.slice(0, 10));\n        await adapter.searchByVector(queries[0]?.embedding || [], config.k);\n      }\n      await adapter.clear();\n    }\n    \n    // Benchmark upsert operations\n    const upsertTimes: number[] = [];\n    for (let run = 0; run < config.runs; run++) {\n      await adapter.clear();\n      \n      const start = performance.now();\n      await adapter.upsert(testChunks);\n      const end = performance.now();\n      \n      upsertTimes.push(end - start);\n    }\n    \n    const avgUpsertTime = upsertTimes.reduce((sum, time) => sum + time, 0) / upsertTimes.length;\n    metrics.push({\n      operation: 'upsert',\n      itemCount: chunkCount,\n      duration: avgUpsertTime,\n      throughput: chunkCount / (avgUpsertTime / 1000),\n      memoryMB: measureMemory(),\n      metadata: {\n        minTime: Math.min(...upsertTimes),\n        maxTime: Math.max(...upsertTimes),\n        stdDev: Math.sqrt(upsertTimes.reduce((sum, time) => sum + Math.pow(time - avgUpsertTime, 2), 0) / upsertTimes.length)\n      }\n    });\n    \n    // Benchmark search operations\n    const searchTimes: number[] = [];\n    for (let run = 0; run < config.runs; run++) {\n      for (const query of queries) {\n        const start = performance.now();\n        const results = await adapter.searchByVector(query.embedding, config.k);\n        const end = performance.now();\n        \n        searchTimes.push(end - start);\n        \n        // Verify results\n        if (results.length === 0 && chunkCount > 0) {\n          console.warn(`  âš ï¸ No results returned for search with ${chunkCount} chunks`);\n        }\n      }\n    }\n    \n    const avgSearchTime = searchTimes.reduce((sum, time) => sum + time, 0) / searchTimes.length;\n    metrics.push({\n      operation: 'search',\n      itemCount: chunkCount,\n      duration: avgSearchTime,\n      throughput: 1000 / avgSearchTime, // Searches per second\n      memoryMB: measureMemory(),\n      metadata: {\n        queriesPerRun: queries.length,\n        minTime: Math.min(...searchTimes),\n        maxTime: Math.max(...searchTimes),\n        p95Time: searchTimes.sort((a, b) => a - b)[Math.floor(searchTimes.length * 0.95)]\n      }\n    });\n  }\n  \n  const peakMemory = Math.max(...metrics.map(m => m.memoryMB || 0));\n  const avgUpsertThroughput = metrics\n    .filter(m => m.operation === 'upsert')\n    .reduce((sum, m) => sum + m.throughput, 0) / \n    metrics.filter(m => m.operation === 'upsert').length;\n    \n  const avgSearchLatency = metrics\n    .filter(m => m.operation === 'search')\n    .reduce((sum, m) => sum + m.duration, 0) /\n    metrics.filter(m => m.operation === 'search').length;\n  \n  // Generate recommendation\n  let recommendation = '';\n  if (avgUpsertThroughput > 1000) {\n    recommendation = 'Excellent performance for production use';\n  } else if (avgUpsertThroughput > 100) {\n    recommendation = 'Good performance for most applications';\n  } else {\n    recommendation = 'Suitable for development and small-scale use';\n  }\n  \n  if (avgSearchLatency > 100) {\n    recommendation += '. Consider optimizing for search latency.';\n  }\n  \n  return {\n    adapterName: adapter.name,\n    config,\n    metrics,\n    summary: {\n      avgUpsertThroughput,\n      avgSearchLatency,\n      peakMemoryMB: peakMemory,\n      recommendation,\n    },\n    timestamp: new Date(),\n  };\n}\n\n/**\n * Benchmark lexical search adapter\n */\nexport async function benchmarkLexicalStore(\n  adapter: LexicalAdapter,\n  config: BenchmarkConfig\n): Promise<BenchmarkResult> {\n  const metrics: PerformanceMetrics[] = [];\n  \n  console.log(`ðŸ”¬ Benchmarking lexical adapter ${adapter.name}...`);\n  \n  for (const chunkCount of config.chunkCounts) {\n    console.log(`  ðŸ“Š Testing with ${chunkCount} chunks...`);\n    \n    // Generate test data\n    const testChunks = generateTestChunks(chunkCount, config.dimensions).map(c => c.chunk);\n    const queries = generateSearchQueries(config.searchQueries);\n    \n    // Benchmark indexing\n    const indexTimes: number[] = [];\n    for (let run = 0; run < config.runs; run++) {\n      const start = performance.now();\n      await adapter.index(testChunks);\n      const end = performance.now();\n      \n      indexTimes.push(end - start);\n    }\n    \n    const avgIndexTime = indexTimes.reduce((sum, time) => sum + time, 0) / indexTimes.length;\n    metrics.push({\n      operation: 'index',\n      itemCount: chunkCount,\n      duration: avgIndexTime,\n      throughput: chunkCount / (avgIndexTime / 1000),\n      memoryMB: measureMemory(),\n    });\n    \n    // Benchmark search\n    const searchTimes: number[] = [];\n    for (let run = 0; run < config.runs; run++) {\n      for (const query of queries) {\n        const start = performance.now();\n        const results = await adapter.search(query.text, config.k);\n        const end = performance.now();\n        \n        searchTimes.push(end - start);\n      }\n    }\n    \n    const avgSearchTime = searchTimes.reduce((sum, time) => sum + time, 0) / searchTimes.length;\n    metrics.push({\n      operation: 'search',\n      itemCount: chunkCount,\n      duration: avgSearchTime,\n      throughput: 1000 / avgSearchTime,\n      memoryMB: measureMemory(),\n    });\n  }\n  \n  const avgIndexThroughput = metrics\n    .filter(m => m.operation === 'index')\n    .reduce((sum, m) => sum + m.throughput, 0) / \n    metrics.filter(m => m.operation === 'index').length;\n    \n  const avgSearchLatency = metrics\n    .filter(m => m.operation === 'search')\n    .reduce((sum, m) => sum + m.duration, 0) /\n    metrics.filter(m => m.operation === 'search').length;\n  \n  return {\n    adapterName: adapter.name,\n    config,\n    metrics,\n    summary: {\n      avgUpsertThroughput: avgIndexThroughput,\n      avgSearchLatency,\n      recommendation: avgSearchLatency < 50 ? 'Excellent lexical search performance' : 'Good lexical search performance',\n    },\n    timestamp: new Date(),\n  };\n}\n\n/**\n * Compare performance between multiple adapters\n */\nexport function compareResults(results: BenchmarkResult[]): ComparisonResult {\n  const bestPerformers: Record<string, string> = {};\n  const ratios: Record<string, Record<string, number>> = {};\n  \n  // Find best performers for each operation\n  const operations = ['upsert', 'search', 'index'];\n  \n  for (const operation of operations) {\n    let bestThroughput = 0;\n    let bestAdapter = '';\n    \n    for (const result of results) {\n      const opMetrics = result.metrics.filter(m => m.operation === operation);\n      if (opMetrics.length > 0) {\n        const avgThroughput = opMetrics.reduce((sum, m) => sum + m.throughput, 0) / opMetrics.length;\n        if (avgThroughput > bestThroughput) {\n          bestThroughput = avgThroughput;\n          bestAdapter = result.adapterName;\n        }\n      }\n    }\n    \n    if (bestAdapter) {\n      bestPerformers[operation] = bestAdapter;\n    }\n  }\n  \n  // Calculate performance ratios\n  for (const result1 of results) {\n    ratios[result1.adapterName] = {};\n    \n    for (const result2 of results) {\n      if (result1.adapterName !== result2.adapterName) {\n        const ratio1 = result1.summary.avgUpsertThroughput / result2.summary.avgUpsertThroughput;\n        const ratiosForAdapter = ratios[result1.adapterName];\n        if (ratiosForAdapter) {\n          ratiosForAdapter[result2.adapterName] = ratio1;\n        }\n      }\n    }\n  }\n  \n  // Generate recommendations\n  const recommendations = {\n    development: results.find(r => r.adapterName.includes('memory'))?.adapterName || \n                results[0]?.adapterName + ' (fast iteration)',\n    production: bestPerformers.upsert || results[0]?.adapterName || 'unknown',\n    largescale: bestPerformers.search || results[0]?.adapterName || 'unknown',\n  };\n  \n  return {\n    results,\n    analysis: {\n      bestPerformers,\n      ratios,\n      recommendations,\n    },\n  };\n}\n\n/**\n * Generate a formatted benchmark report\n */\nexport function generateReport(comparison: ComparisonResult): string {\n  const { results, analysis } = comparison;\n  \n  let report = '# Orquel Performance Benchmark Report\\n\\n';\n  report += `Generated: ${new Date().toISOString()}\\n\\n`;\n  \n  // Summary table\n  report += '## Summary\\n\\n';\n  report += '| Adapter | Avg Upsert Throughput | Avg Search Latency | Peak Memory | Recommendation |\\n';\n  report += '|---------|----------------------|-------------------|-------------|----------------|\\n';\n  \n  for (const result of results) {\n    const throughput = result.summary.avgUpsertThroughput.toFixed(1);\n    const latency = result.summary.avgSearchLatency.toFixed(2);\n    const memory = result.summary.peakMemoryMB?.toFixed(1) || 'N/A';\n    const rec = result.summary.recommendation;\n    \n    report += `| ${result.adapterName} | ${throughput} items/s | ${latency}ms | ${memory}MB | ${rec} |\\n`;\n  }\n  \n  report += '\\n## Best Performers\\n\\n';\n  for (const [operation, adapter] of Object.entries(analysis.bestPerformers)) {\n    report += `- **${operation}**: ${adapter}\\n`;\n  }\n  \n  report += '\\n## Recommendations\\n\\n';\n  report += `- **Development**: ${analysis.recommendations.development}\\n`;\n  report += `- **Production**: ${analysis.recommendations.production}\\n`;\n  report += `- **Large Scale**: ${analysis.recommendations.largescale}\\n`;\n  \n  report += '\\n## Detailed Metrics\\n\\n';\n  for (const result of results) {\n    report += `### ${result.adapterName}\\n\\n`;\n    \n    for (const metric of result.metrics) {\n      report += `**${metric.operation}** (${metric.itemCount} items):\\n`;\n      report += `- Duration: ${metric.duration.toFixed(2)}ms\\n`;\n      report += `- Throughput: ${metric.throughput.toFixed(2)} ops/s\\n`;\n      if (metric.memoryMB) {\n        report += `- Memory: ${metric.memoryMB.toFixed(1)}MB\\n`;\n      }\n      report += '\\n';\n    }\n  }\n  \n  return report;\n}\n\n/**\n * Default benchmark configuration for quick testing\n */\nexport const DEFAULT_BENCHMARK_CONFIG: BenchmarkConfig = {\n  chunkCounts: [10, 50, 100, 500],\n  dimensions: 1536, // OpenAI text-embedding-3-small\n  searchQueries: 5,\n  k: 10,\n  runs: 3,\n  warmupRuns: 1,\n};\n\n/**\n * Comprehensive benchmark configuration for thorough testing\n */\nexport const COMPREHENSIVE_BENCHMARK_CONFIG: BenchmarkConfig = {\n  chunkCounts: [100, 500, 1000, 5000, 10000],\n  dimensions: 1536,\n  searchQueries: 20,\n  k: 10,\n  runs: 5,\n  warmupRuns: 3,\n};"],"mappings":";;;;;;;;;;;;;;;;;;;;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;;;ACCA,yBAA2B;AAQ3B,IAAM,kBAA4C;AAAA,EAChD,cAAc;AAAA,EACd,SAAS;AAAA,EACT,yBAAyB;AAC3B;AAyBO,SAAS,eACd,MACA,QACA,UAA0B,CAAC,GAClB;AACT,QAAM,OAAO,EAAE,GAAG,iBAAiB,GAAG,QAAQ;AAG9C,QAAM,aAAa,cAAc,IAAI;AAErC,MAAI,WAAW,WAAW,GAAG;AAC3B,WAAO,CAAC;AAAA,EACV;AAEA,MAAI,WAAW,UAAU,KAAK,cAAc;AAC1C,WAAO,CAAC,YAAY,YAAY,QAAQ,CAAC,CAAC;AAAA,EAC5C;AAEA,QAAM,SAAkB,CAAC;AACzB,MAAI,aAAa;AAEjB,MAAI,KAAK,2BAA2B,OAAO,SAAS,MAAM;AACxD,UAAM,WAAW,wBAAwB,UAAU;AAEnD,eAAW,WAAW,UAAU;AAC9B,UAAI,QAAQ,UAAU,KAAK,cAAc;AACvC,eAAO,KAAK,YAAY,SAAS,QAAQ,YAAY,CAAC;AAAA,MACxD,OAAO;AACL,cAAM,YAAY,oBAAoB,SAAS,KAAK,cAAc,KAAK,OAAO;AAC9E,mBAAW,YAAY,WAAW;AAChC,iBAAO,KAAK,YAAY,UAAU,QAAQ,YAAY,CAAC;AAAA,QACzD;AAAA,MACF;AAAA,IACF;AAAA,EACF,OAAO;AACL,UAAM,aAAa,oBAAoB,YAAY,KAAK,cAAc,KAAK,OAAO;AAClF,eAAW,SAAS,YAAY;AAC9B,aAAO,KAAK,YAAY,OAAO,QAAQ,YAAY,CAAC;AAAA,IACtD;AAAA,EACF;AAEA,SAAO,kBAAkB,MAAM;AACjC;AAEA,SAAS,cAAc,MAAsB;AAC3C,SAAO,KACJ,KAAK,EACL,QAAQ,SAAS,IAAI,EACrB,QAAQ,WAAW,GAAG,EACtB,QAAQ,WAAW,MAAM;AAC9B;AAEA,SAAS,wBAAwB,MAAwB;AACvD,QAAM,WAAqB,CAAC;AAC5B,QAAM,QAAQ,KAAK,MAAM,IAAI;AAC7B,MAAI,iBAAiB;AAErB,aAAW,QAAQ,OAAO;AACxB,QAAI,KAAK,MAAM,WAAW,GAAG;AAC3B,UAAI,eAAe,KAAK,GAAG;AACzB,iBAAS,KAAK,eAAe,KAAK,CAAC;AAAA,MACrC;AACA,uBAAiB,OAAO;AAAA,IAC1B,OAAO;AACL,wBAAkB,OAAO;AAAA,IAC3B;AAAA,EACF;AAEA,MAAI,eAAe,KAAK,GAAG;AACzB,aAAS,KAAK,eAAe,KAAK,CAAC;AAAA,EACrC;AAEA,SAAO,SAAS,OAAO,OAAK,EAAE,SAAS,CAAC;AAC1C;AAEA,SAAS,oBAAoB,MAAc,SAAiB,SAA2B;AACrF,MAAI,KAAK,UAAU,SAAS;AAC1B,WAAO,CAAC,IAAI;AAAA,EACd;AAEA,QAAM,SAAmB,CAAC;AAC1B,MAAI,QAAQ;AAEZ,SAAO,QAAQ,KAAK,QAAQ;AAC1B,QAAI,MAAM,QAAQ;AAElB,QAAI,OAAO,KAAK,QAAQ;AACtB,aAAO,KAAK,KAAK,MAAM,KAAK,CAAC;AAC7B;AAAA,IACF;AAGA,UAAM,aAAa,eAAe,MAAM,OAAO,GAAG;AAClD,WAAO,KAAK,KAAK,MAAM,OAAO,UAAU,CAAC;AAEzC,YAAQ,KAAK,IAAI,QAAQ,GAAG,aAAa,OAAO;AAAA,EAClD;AAEA,SAAO;AACT;AAEA,SAAS,eAAe,MAAc,OAAe,KAAqB;AAExE,WAAS,IAAI,MAAM,GAAG,IAAI,SAAS,MAAM,SAAS,KAAK,KAAK;AAC1D,QAAI,KAAK,CAAC,MAAM,OAAO,KAAK,IAAI,CAAC,MAAM,KAAK;AAC1C,aAAO,IAAI;AAAA,IACb;AAAA,EACF;AAGA,WAAS,IAAI,MAAM,GAAG,IAAI,SAAS,MAAM,SAAS,KAAK,KAAK;AAC1D,QAAI,KAAK,CAAC,MAAM,KAAK;AACnB,aAAO;AAAA,IACT;AAAA,EACF;AAEA,SAAO;AACT;AAEA,SAAS,YAAY,MAAc,QAAsB,YAA2B;AAClF,QAAM,WAAO,+BAAW,QAAQ,EAAE,OAAO,IAAI,EAAE,OAAO,KAAK,EAAE,MAAM,GAAG,EAAE;AAExE,SAAO;AAAA,IACL,IAAI,GAAG,OAAO,KAAK,IAAI,UAAU,IAAI,IAAI;AAAA,IACzC;AAAA,IACA,OAAO;AAAA,IACP;AAAA,IACA,QAAQ;AAAA,MACN,OAAO,OAAO;AAAA,MACd,GAAI,OAAO,QAAQ,EAAE,MAAM,OAAO,KAAK;AAAA,IACzC;AAAA,IACA,UAAU,CAAC;AAAA,EACb;AACF;AAEA,SAAS,kBAAkB,QAA0B;AACnD,QAAM,OAAO,oBAAI,IAAY;AAC7B,SAAO,OAAO,OAAO,WAAS;AAC5B,QAAI,KAAK,IAAI,MAAM,IAAI,GAAG;AACxB,aAAO;AAAA,IACT;AACA,SAAK,IAAI,MAAM,IAAI;AACnB,WAAO;AAAA,EACT,CAAC;AACH;;;AClKO,IAAM,cAAN,MAAkB;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,EAcvB,OAAO,cAAc,OAAsB;AACzC,UAAM,QAAQ,MAAM,UAAU,QAAQ;AACtC,QAAI,CAAC,OAAO;AACV,cAAQ,KAAK,qDAAqD;AAClE,aAAO;AAAA,IACT;AACA,WAAO;AAAA,EACT;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,EAeA,OAAO,sBAAsB,QAA2B;AACtD,UAAM,SAAS,OACZ,IAAI,WAAS,MAAM,UAAU,QAAQ,KAAK,EAC1C,OAAO,CAAC,UAA2B,QAAQ,KAAK,CAAC;AAEpD,WAAO,CAAC,GAAG,IAAI,IAAI,MAAM,CAAC;AAAA,EAC5B;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,EAmBA,OAAO,oBAAoB,SAAgC;AACzD,QAAI,QAAQ,WAAW,GAAG;AACxB,aAAO;AAAA,IACT;AAEA,WAAO,QAAQ,IAAI,CAAC,QAAQ,UAAU;AACpC,YAAM,QAAQ,KAAK,cAAc,OAAO,KAAK;AAC7C,YAAM,QAAQ,OAAO,MAAM,QAAQ,CAAC;AACpC,aAAO,GAAG,QAAQ,CAAC,KAAK,KAAK,KAAK,KAAK;AAAA,IACzC,CAAC,EAAE,KAAK,IAAI;AAAA,EACd;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,EAkBA,OAAO,cAAc,OAAwC;AAC3D,QAAI,CAAC,SAAS,OAAO,UAAU,UAAU;AACvC,YAAM,IAAI,MAAM,yBAAyB;AAAA,IAC3C;AAEA,UAAM,IAAI;AAEV,QAAI,OAAO,EAAE,OAAO,UAAU;AAC5B,YAAM,IAAI,MAAM,6BAA6B;AAAA,IAC/C;AAEA,QAAI,OAAO,EAAE,SAAS,UAAU;AAC9B,YAAM,IAAI,MAAM,wCAAwC;AAAA,IAC1D;AAEA,QAAI,CAAC,EAAE,YAAY,OAAO,EAAE,aAAa,UAAU;AACjD,YAAM,IAAI,MAAM,mCAAmC;AAAA,IACrD;AAEA,QAAI,CAAC,EAAE,SAAS,UAAU,OAAO,EAAE,SAAS,WAAW,UAAU;AAC/D,YAAM,IAAI,MAAM,0CAA0C;AAAA,IAC5D;AAEA,QAAI,OAAO,EAAE,SAAS,OAAO,UAAU,UAAU;AAC/C,YAAM,IAAI,MAAM,gDAAgD;AAAA,IAClE;AAAA,EACF;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,EAkBA,OAAO,aAAa,OAAoB;AACtC,YAAQ,IAAI,6BAAsB;AAClC,YAAQ,IAAI,cAAS,MAAM,EAAE,EAAE;AAC/B,YAAQ,IAAI,uBAAkB,MAAM,KAAK,MAAM,aAAa;AAC5D,YAAQ,IAAI,mBAAc,KAAK,cAAc,KAAK,CAAC,GAAG;AACtD,YAAQ,IAAI,uBAAkB,MAAM,UAAU,cAAc,SAAS,EAAE;AACvE,YAAQ,IAAI,oBAAe,MAAM,UAAU,OAAO,QAAQ,IAAI,EAAE;AAEhE,QAAI,MAAM,KAAK,SAAS,KAAK;AAC3B,cAAQ,IAAI,yBAAoB,MAAM,KAAK,UAAU,GAAG,GAAG,CAAC,MAAM;AAAA,IACpE,OAAO;AACL,cAAQ,IAAI,sBAAiB,MAAM,IAAI,GAAG;AAAA,IAC5C;AAAA,EACF;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,EAaA,OAAO,oBAAoB,SAA8B;AACvD,YAAQ,IAAI,qCAA8B;AAC1C,YAAQ,IAAI,wBAAmB,QAAQ,MAAM,EAAE;AAE/C,QAAI,QAAQ,SAAS,GAAG;AACtB,cAAQ,IAAI,uBAAkB,QAAQ,QAAQ,SAAS,CAAC,EAAG,MAAM,QAAQ,CAAC,CAAC,MAAM,QAAQ,CAAC,EAAG,MAAM,QAAQ,CAAC,CAAC,EAAE;AAC/G,cAAQ,IAAI,uBAAkB;AAE9B,YAAM,UAAU,KAAK,sBAAsB,QAAQ,IAAI,OAAK,EAAE,KAAK,CAAC;AACpE,cAAQ,QAAQ,YAAU,QAAQ,IAAI,OAAO,MAAM,EAAE,CAAC;AAEtD,cAAQ,IAAI,uBAAkB;AAC9B,WAAK,aAAa,QAAQ,CAAC,EAAG,KAAK;AAAA,IACrC;AAAA,EACF;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,EAgBA,OAAO,kBAAkB,UAA2B;AAClD,UAAM,UAAU,KAAK,sBAAsB,QAAQ;AACnD,UAAM,aAAa,SAAS;AAC5B,UAAM,cAAc,QAAQ;AAE5B,QAAI,eAAe,GAAG;AACpB,aAAO;AAAA,IACT;AAEA,UAAM,aAAa,QAAQ,KAAK,IAAI;AACpC,WAAO,YAAY,UAAU,SAAS,eAAe,IAAI,KAAK,GAAG,SAAS,WAAW,UAAU,gBAAgB,IAAI,KAAK,GAAG,KAAK,UAAU;AAAA,EAC5I;AACF;;;AChNO,SAAS,qBACd,cACA,gBACA,IAAY,IACZ,cAAsB,IACN;AAEhB,QAAM,aAAa,oBAAI,IAAoB;AAC3C,QAAM,eAAe,oBAAI,IAAoB;AAG7C,eAAa,QAAQ,CAAC,QAAQ,UAAU;AACtC,eAAW,IAAI,OAAO,MAAM,IAAI,QAAQ,CAAC;AAAA,EAC3C,CAAC;AAED,iBAAe,QAAQ,CAAC,QAAQ,UAAU;AACxC,iBAAa,IAAI,OAAO,MAAM,IAAI,QAAQ,CAAC;AAAA,EAC7C,CAAC;AAGD,QAAM,cAAc,oBAAI,IAAI;AAAA,IAC1B,GAAG,aAAa,IAAI,OAAK,EAAE,MAAM,EAAE;AAAA,IACnC,GAAG,eAAe,IAAI,OAAK,EAAE,MAAM,EAAE;AAAA,EACvC,CAAC;AAGD,QAAM,aAA+F,CAAC;AAEtG,aAAW,WAAW,aAAa;AACjC,QAAI,WAAW;AACf,QAAI,QAAsC;AAG1C,UAAM,YAAY,WAAW,IAAI,OAAO;AACxC,QAAI,cAAc,QAAW;AAC3B,kBAAY,KAAK,cAAc;AAC/B,cAAQ,aAAa,KAAK,OAAK,EAAE,MAAM,OAAO,OAAO,GAAG,SAAS;AAAA,IACnE;AAGA,UAAM,cAAc,aAAa,IAAI,OAAO;AAC5C,QAAI,gBAAgB,QAAW;AAC7B,kBAAY,KAAK,cAAc;AAC/B,UAAI,CAAC,OAAO;AACV,gBAAQ,eAAe,KAAK,OAAK,EAAE,MAAM,OAAO,OAAO,GAAG,SAAS;AAAA,MACrE;AAAA,IACF;AAEA,QAAI,OAAO;AACT,iBAAW,KAAK,EAAE,IAAI,SAAS,OAAO,UAAU,OAAO,MAAM,EAAE,CAAC;AAAA,IAClE;AAAA,EACF;AAGA,aAAW,KAAK,CAAC,GAAG,MAAM,EAAE,QAAQ,EAAE,KAAK;AAE3C,SAAO,WAAW,MAAM,GAAG,CAAC,EAAE,IAAI,CAAC,QAAQ,WAAW;AAAA,IACpD,OAAO,OAAO;AAAA,IACd,OAAO,OAAO;AAAA,IACd,MAAM,QAAQ;AAAA,EAChB,EAAE;AACJ;AAMO,SAAS,yBACd,cACA,gBACA,IAAY,IACZ,cAAsB,KACtB,gBAAwB,KACR;AAEhB,QAAM,kBAAkB,gBAAgB,YAAY;AACpD,QAAM,oBAAoB,gBAAgB,cAAc;AAGxD,QAAM,WAAW,oBAAI,IAA0B;AAG/C,aAAW,UAAU,iBAAiB;AACpC,aAAS,IAAI,OAAO,MAAM,IAAI;AAAA,MAC5B,GAAG;AAAA,MACH,OAAO,OAAO,QAAQ;AAAA,IACxB,CAAC;AAAA,EACH;AAGA,aAAW,UAAU,mBAAmB;AACtC,UAAM,WAAW,SAAS,IAAI,OAAO,MAAM,EAAE;AAC7C,QAAI,UAAU;AACZ,eAAS,SAAS,OAAO,QAAQ;AAAA,IACnC,OAAO;AACL,eAAS,IAAI,OAAO,MAAM,IAAI;AAAA,QAC5B,GAAG;AAAA,QACH,OAAO,OAAO,QAAQ;AAAA,MACxB,CAAC;AAAA,IACH;AAAA,EACF;AAGA,QAAM,gBAAgB,MAAM,KAAK,SAAS,OAAO,CAAC,EAC/C,KAAK,CAAC,GAAG,MAAM,EAAE,QAAQ,EAAE,KAAK,EAChC,MAAM,GAAG,CAAC;AAGb,SAAO,cAAc,IAAI,CAAC,QAAQ,WAAW;AAAA,IAC3C,GAAG;AAAA,IACH,MAAM,QAAQ;AAAA,EAChB,EAAE;AACJ;AAKA,SAAS,sBAAsB,SAAyC;AACtE,MAAI,QAAQ,WAAW,EAAG,QAAO;AAEjC,QAAM,SAAS,QAAQ,IAAI,OAAK,EAAE,KAAK;AACvC,QAAM,MAAM,KAAK,IAAI,GAAG,MAAM;AAC9B,QAAM,MAAM,KAAK,IAAI,GAAG,MAAM;AAG9B,MAAI,QAAQ,KAAK;AACf,WAAO,QAAQ,IAAI,aAAW,EAAE,GAAG,QAAQ,OAAO,EAAE,EAAE;AAAA,EACxD;AAEA,SAAO,QAAQ,IAAI,aAAW;AAAA,IAC5B,GAAG;AAAA,IACH,QAAQ,OAAO,QAAQ,QAAQ,MAAM;AAAA,EACvC,EAAE;AACJ;AAKA,SAAS,sBAAsB,SAAyC;AACtE,MAAI,QAAQ,WAAW,EAAG,QAAO;AACjC,MAAI,QAAQ,WAAW,EAAG,QAAO,QAAQ,IAAI,QAAM,EAAE,GAAG,GAAG,OAAO,EAAE,EAAE;AAEtE,QAAM,SAAS,QAAQ,IAAI,OAAK,EAAE,KAAK;AACvC,QAAM,OAAO,OAAO,OAAO,CAAC,KAAK,UAAU,MAAM,OAAO,CAAC,IAAI,OAAO;AACpE,QAAM,WAAW,OAAO,OAAO,CAAC,KAAK,UAAU,MAAM,KAAK,IAAI,QAAQ,MAAM,CAAC,GAAG,CAAC,IAAI,OAAO;AAC5F,QAAM,SAAS,KAAK,KAAK,QAAQ;AAGjC,MAAI,WAAW,GAAG;AAChB,WAAO,QAAQ,IAAI,aAAW,EAAE,GAAG,QAAQ,OAAO,EAAE,EAAE;AAAA,EACxD;AAGA,SAAO,QAAQ,IAAI,YAAU;AAC3B,UAAM,UAAU,OAAO,QAAQ,QAAQ;AACvC,UAAM,kBAAkB,KAAK,IAAI,KAAK,IAAI,CAAC,MAAM;AACjD,WAAO,EAAE,GAAG,QAAQ,OAAO,gBAAgB;AAAA,EAC7C,CAAC;AACH;AAKO,SAAS,gBACd,SACA,SAA8B,UACd;AAChB,UAAQ,QAAQ;AAAA,IACd,KAAK;AACH,aAAO,sBAAsB,OAAO;AAAA,IACtC,KAAK;AACH,aAAO,sBAAsB,OAAO;AAAA,IACtC;AACE,aAAO,sBAAsB,OAAO;AAAA,EACxC;AACF;AAKO,SAAS,mBACd,cACA,gBACA,SACgB;AAChB,QAAM;AAAA,IACJ,IAAI;AAAA,IACJ,cAAc;AAAA,IACd,gBAAgB;AAAA,IAChB,sBAAsB;AAAA,EACxB,IAAI;AAEJ,UAAQ,qBAAqB;AAAA,IAC3B,KAAK;AACH,aAAO,qBAAqB,cAAc,gBAAgB,CAAC;AAAA,IAC7D,KAAK;AAAA,IACL,KAAK;AACH,aAAO;AAAA,QACL;AAAA,QACA;AAAA,QACA;AAAA,QACA;AAAA,QACA;AAAA,MACF;AAAA,IACF;AACE,aAAO,qBAAqB,cAAc,gBAAgB,CAAC;AAAA,EAC/D;AACF;AAMO,SAAS,qBACd,cACA,gBAOA;AACA,QAAM,WAAW,IAAI,IAAI,aAAa,IAAI,OAAK,EAAE,MAAM,EAAE,CAAC;AAC1D,QAAM,aAAa,IAAI,IAAI,eAAe,IAAI,OAAK,EAAE,MAAM,EAAE,CAAC;AAE9D,QAAM,aAAa,IAAI,IAAI,CAAC,GAAG,QAAQ,EAAE,OAAO,QAAM,WAAW,IAAI,EAAE,CAAC,CAAC;AAEzE,QAAM,iBAAiB,SAAS,OAAO,WAAW;AAClD,QAAM,mBAAmB,WAAW,OAAO,WAAW;AACtD,QAAM,eAAe,WAAW;AAEhC,QAAM,cAAc,SAAS,OAAO,WAAW,OAAO,WAAW;AACjE,QAAM,oBAAoB,cAAc,IAAK,eAAe,cAAe,MAAM;AAIjF,QAAM,qBAAqB,cAAc,KAAK,iBAAiB,oBAAoB,cAAc;AAEjG,SAAO;AAAA,IACL;AAAA,IACA;AAAA,IACA;AAAA,IACA;AAAA,IACA;AAAA,EACF;AACF;;;ACnOO,SAAS,aAAa,QAA8B;AACzD,QAAM,UAAU,OAAO,YAAY,CAAC,SAClC,eAAe,MAAM,EAAE,OAAO,UAAU,CAAC;AAE3C,QAAM,QAAQ,OAAO,SAAS;AAE9B,MAAI,OAAO;AACT,YAAQ,IAAI,qCAA8B;AAC1C,YAAQ,IAAI,0BAAmB;AAC/B,YAAQ,IAAI,wBAAmB,OAAO,WAAW,IAAI,EAAE;AACvD,YAAQ,IAAI,0BAAqB,OAAO,OAAO,IAAI,EAAE;AACrD,YAAQ,IAAI,qBAAgB,OAAO,SAAS,QAAQ,MAAM,EAAE;AAC5D,YAAQ,IAAI,sBAAiB,OAAO,UAAU,QAAQ,MAAM,EAAE;AAC9D,YAAQ,IAAI,sBAAiB,OAAO,UAAU,QAAQ,MAAM,EAAE;AAAA,EAChE;AAEA,SAAO;AAAA,IACL,MAAM,OAAO,MAAkB;AAC7B,UAAI,OAAO;AACT,gBAAQ,IAAI,yBAAkB,KAAK,OAAO,KAAK,GAAG;AAClD,gBAAQ,IAAI,6BAAsB,OAAO,KAAK,YAAY,WAAW,KAAK,QAAQ,SAAS,KAAK,QAAQ,UAAU,IAAI,OAAO,KAAK,YAAY,WAAW,eAAe,OAAO,EAAE;AAAA,MACnL;AAEA,YAAM,UAAU,OAAO,KAAK,YAAY,WACpC,KAAK,UACL,KAAK,QAAQ,SAAS,OAAO;AAEjC,YAAM,SAAS,QAAQ,OAAO;AAE9B,UAAI,OAAO;AACT,gBAAQ,IAAI,8BAAoB,OAAO,MAAM,SAAS;AACtD,YAAI,OAAO,SAAS,GAAG;AACrB,kBAAQ,IAAI,+BAAwB,KAAK,IAAI,GAAG,OAAO,IAAI,OAAK,EAAE,KAAK,MAAM,CAAC,CAAC,IAAI,KAAK,IAAI,GAAG,OAAO,IAAI,OAAK,EAAE,KAAK,MAAM,CAAC,CAAC,aAAa;AAAA,QAC7I;AAAA,MACF;AAGA,YAAM,gBAAgB,OAAO,IAAI,YAAU;AAAA,QACzC,GAAG;AAAA,QACH,UAAU;AAAA,UACR,GAAG,MAAM;AAAA,UACT,QAAQ,KAAK;AAAA,QACf;AAAA,MACF,EAAE;AAGF,UAAI,SAAS,cAAc,SAAS,GAAG;AACrC,YAAI;AACF,sBAAY,cAAc,cAAc,CAAC,CAAC;AAC1C,kBAAQ,IAAI,0CAAqC;AAAA,QACnD,SAAS,OAAO;AACd,kBAAQ,KAAK,2CAAiC,KAAK;AAAA,QACrD;AAAA,MACF;AAEA,aAAO;AAAA,QACL,UAAU,KAAK,OAAO;AAAA,QACtB,QAAQ;AAAA,MACV;AAAA,IACF;AAAA,IAEA,MAAM,MAAM,QAAiB;AAC3B,UAAI,OAAO;AACT,gBAAQ,IAAI,sBAAe,OAAO,MAAM,YAAY;AAAA,MACtD;AAGA,YAAM,QAAQ,OAAO,IAAI,WAAS,MAAM,IAAI;AAC5C,YAAM,aAAa,MAAM,OAAO,WAAW,MAAM,KAAK;AAEtD,UAAI,OAAO;AACT,gBAAQ,IAAI,uBAAgB,WAAW,MAAM,gBAAgB,OAAO,WAAW,GAAG,IAAI;AAAA,MACxF;AAGA,YAAM,OAAO,OAAO,IAAI,CAAC,OAAO,OAAO;AAAA,QACrC;AAAA,QACA,WAAW,WAAW,CAAC;AAAA,MACzB,EAAE;AAGF,YAAM,OAAO,OAAO,OAAO,IAAI;AAG/B,UAAI,OAAO,SAAS;AAClB,cAAM,OAAO,QAAQ,MAAM,MAAM;AACjC,YAAI,OAAO;AACT,kBAAQ,IAAI,uCAAgC,OAAO,QAAQ,IAAI,EAAE;AAAA,QACnE;AAAA,MACF;AAEA,UAAI,OAAO;AACT,gBAAQ,IAAI,2BAAsB;AAAA,MACpC;AAAA,IACF;AAAA,IAEA,MAAM,MAAM,GAAW,OAAqB,CAAC,GAAG;AAC9C,UAAI,OAAO;AACT,gBAAQ,IAAI,wBAAiB,CAAC,GAAG;AACjC,gBAAQ,IAAI,4BAAkB,KAAK,KAAK,EAAE,YAAY,KAAK,UAAU,CAAC,CAAC,OAAO,OAAO,YAAY,KAAK,UAAU,CAAC,CAAC,OAAO,QAAQ,EAAE;AAAA,MACrI;AAEA,YAAM,EAAE,IAAI,IAAI,SAAS,CAAC,CAAC,OAAO,SAAS,SAAS,CAAC,CAAC,OAAO,SAAS,IAAI;AAE1E,UAAI,UAA0B,CAAC;AAE/B,UAAI,UAAU,OAAO,SAAS;AAC5B,YAAI,OAAO;AACT,kBAAQ,IAAI,iDAA0C;AAAA,QACxD;AAEA,cAAM,CAAC,cAAc,IAAI,MAAM,OAAO,WAAW,MAAM,CAAC,CAAC,CAAC;AAC1D,cAAM,eAAe,MAAM,OAAO,OAAO,eAAe,gBAAiB,CAAC;AAC1E,cAAM,iBAAiB,MAAM,OAAO,QAAQ,OAAO,GAAG,CAAC;AAEvD,YAAI,OAAO;AACT,kBAAQ,IAAI,4BAAqB,aAAa,MAAM,sBAAsB,eAAe,MAAM,EAAE;AAAA,QACnG;AAGA,YAAI,OAAO;AACT,gBAAM,UAAU,qBAAqB,cAAc,cAAc;AACjE,kBAAQ,IAAI,6BAAsB,QAAQ,YAAY,YAAY,QAAQ,cAAc,gBAAgB,QAAQ,gBAAgB,eAAe;AAC/I,kBAAQ,IAAI,mCAA4B,QAAQ,qBAAqB,KAAK,QAAQ,CAAC,CAAC,GAAG;AAAA,QACzF;AAGA,cAAM,gBAAgB,OAAO,UAAU,CAAC;AACxC,kBAAU,mBAAmB,cAAc,gBAAgB,EAAE,GAAG,eAAe,EAAE,CAAC;AAAA,MACpF,OAAO;AACL,YAAI,OAAO;AACT,kBAAQ,IAAI,mCAA4B;AAAA,QAC1C;AAEA,cAAM,CAAC,cAAc,IAAI,MAAM,OAAO,WAAW,MAAM,CAAC,CAAC,CAAC;AAC1D,kBAAU,MAAM,OAAO,OAAO,eAAe,gBAAiB,CAAC;AAAA,MACjE;AAGA,UAAI,UAAU,OAAO,YAAY,QAAQ,SAAS,GAAG;AACnD,YAAI,OAAO;AACT,kBAAQ,IAAI,qCAA8B,OAAO,SAAS,IAAI,EAAE;AAAA,QAClE;AACA,cAAM,SAAS,QAAQ,IAAI,OAAK,EAAE,KAAK;AACvC,cAAM,kBAAkB,MAAM,OAAO,SAAS,OAAO,GAAG,MAAM;AAC9D,kBAAU,gBAAgB,IAAI,SAAO,QAAQ,GAAG,CAAE;AAAA,MACpD;AAEA,UAAI,OAAO;AACT,gBAAQ,IAAI,4BAAqB,QAAQ,MAAM,EAAE;AACjD,YAAI,QAAQ,SAAS,GAAG;AACtB,sBAAY,oBAAoB,OAAO;AAAA,QACzC;AAAA,MACF;AAEA,aAAO,EAAE,QAAQ;AAAA,IACnB;AAAA,IAEA,MAAM,OAAO,GAAW,OAAsB,CAAC,GAAG;AAChD,UAAI,OAAO;AACT,gBAAQ,IAAI,qCAA8B,CAAC,GAAG;AAC9C,gBAAQ,IAAI,+BAAqB,KAAK,QAAQ,CAAC,EAAE;AAAA,MACnD;AAEA,YAAM,EAAE,OAAO,EAAE,IAAI;AAErB,UAAI,CAAC,OAAO,UAAU;AACpB,cAAM,IAAI,MAAM,wBAAwB;AAAA,MAC1C;AAGA,YAAM,EAAE,QAAQ,IAAI,MAAM,KAAK,MAAM,GAAG,EAAE,GAAG,KAAK,CAAC;AACnD,YAAM,WAAW,QAAQ,IAAI,OAAK,EAAE,KAAK;AAEzC,UAAI,OAAO;AACT,gBAAQ,IAAI,mBAAY,SAAS,MAAM,iCAAiC;AACxE,gBAAQ,IAAI,oCAA6B,OAAO,SAAS,IAAI,KAAK;AAClE,gBAAQ,IAAI,8BAAuB,YAAY,kBAAkB,QAAQ,CAAC;AAAA,MAC5E;AAGA,YAAM,SAAS,MAAM,OAAO,SAAS,OAAO;AAAA,QAC1C,OAAO;AAAA,QACP;AAAA,MACF,CAAC;AAED,UAAI,OAAO;AACT,gBAAQ,IAAI,4BAAuB,OAAO,MAAM,cAAc;AAC9D,YAAI,OAAO,SAAS,KAAK;AACvB,kBAAQ,IAAI,8BAAuB,OAAO,UAAU,GAAG,GAAG,CAAC,MAAM;AAAA,QACnE,OAAO;AACL,kBAAQ,IAAI,2BAAoB,MAAM,GAAG;AAAA,QAC3C;AAAA,MACF;AAEA,aAAO,EAAE,QAAQ,SAAS;AAAA,IAC5B;AAAA,EACF;AACF;;;AC5JO,IAAM,eAAN,MAAmB;AAAA,EAChB;AAAA,EAER,YAAY,QAAgB;AAC1B,SAAK,SAAS;AAAA,EAChB;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,EAsBA,MAAM,SACJ,oBACA,SAA2B,CAAC,GACA;AAC5B,UAAM;AAAA,MACJ,IAAI;AAAA,MACJ,SAAS;AAAA,MACT,SAAS;AAAA,MACT,kBAAkB;AAAA,IACpB,IAAI;AAEJ,UAAM,eAAwC,CAAC;AAC/C,QAAI,oBAAoB;AAExB,eAAW,eAAe,oBAAoB;AAC5C,YAAM,YAAY,KAAK,IAAI;AAE3B,UAAI;AAEF,cAAM,EAAE,QAAQ,IAAI,MAAM,KAAK,OAAO,MAAM,YAAY,OAAO;AAAA,UAC7D;AAAA,UACA;AAAA,UACA;AAAA,QACF,CAAC;AAED,cAAM,eAAe,KAAK,IAAI,IAAI;AAClC,6BAAqB;AAGrB,cAAM,oBAAoB,QAAQ,IAAI,OAAK,EAAE,MAAM,EAAE;AACrD,cAAM,aAAa,KAAK;AAAA,UACtB,YAAY;AAAA,UACZ;AAAA,UACA,YAAY;AAAA,UACZ;AAAA,QACF;AAGA,YAAI;AACJ,YAAI;AAEJ,YAAI,mBAAmB,YAAY,gBAAgB;AACjD,cAAI;AACF,kBAAM,eAAe,MAAM,KAAK,OAAO,OAAO,YAAY,KAAK;AAC/D,qBAAS,aAAa;AACtB,0BAAc,KAAK;AAAA,cACjB;AAAA,cACA,YAAY;AAAA,cACZ,YAAY;AAAA,YACd;AAAA,UACF,SAAS,aAAa;AACpB,oBAAQ,KAAK,uCAAuC,YAAY,KAAK,MAAM,WAAW;AAAA,UAExF;AAAA,QACF;AAEA,cAAM,SAAgC;AAAA,UACpC,GAAG;AAAA,UACH;AAAA,QACF;AAEA,YAAI,WAAW,QAAW;AACxB,iBAAO,SAAS;AAAA,QAClB;AACA,YAAI,gBAAgB,QAAW;AAC7B,iBAAO,cAAc;AAAA,QACvB;AAEA,qBAAa,KAAK,MAAM;AAAA,MAC1B,SAAS,OAAO;AACd,gBAAQ,KAAK,6BAA6B,YAAY,KAAK,MAAM,KAAK;AAGtE,qBAAa,KAAK;AAAA,UAChB,OAAO,YAAY;AAAA,UACnB,mBAAmB,CAAC;AAAA,UACpB,kBAAkB,YAAY;AAAA,UAC9B,WAAW;AAAA,UACX,QAAQ;AAAA,UACR,SAAS;AAAA,UACT,gBAAgB;AAAA,UAChB,KAAK;AAAA,UACL,MAAM;AAAA,UACN,mBAAmB;AAAA,UACnB,cAAc,KAAK,IAAI,IAAI;AAAA,QAC7B,CAAC;AAAA,MACH;AAAA,IACF;AAEA,WAAO,KAAK,iBAAiB,cAAc,iBAAiB;AAAA,EAC9D;AAAA;AAAA;AAAA;AAAA,EAKQ,cACN,OACA,mBACA,kBACA,SACuB;AACvB,UAAM,cAAc,IAAI,IAAI,gBAAgB;AAC5C,UAAM,oBAAoB,kBAAkB,OAAO,QAAM,YAAY,IAAI,EAAE,CAAC;AAG5E,UAAM,YAAY,kBAAkB,SAAS,IACzC,kBAAkB,SAAS,kBAAkB,SAC7C;AAEJ,UAAM,SAAS,iBAAiB,SAAS,IACrC,kBAAkB,SAAS,iBAAiB,SAC5C;AAGJ,UAAM,UAAU,YAAY,SAAS,IAChC,IAAI,YAAY,UAAW,YAAY,UACxC;AAGJ,QAAI,iBAAiB;AACrB,aAAS,IAAI,GAAG,IAAI,kBAAkB,QAAQ,KAAK;AACjD,UAAI,YAAY,IAAI,kBAAkB,CAAC,CAAE,GAAG;AAC1C,yBAAiB,KAAK,IAAI;AAC1B;AAAA,MACF;AAAA,IACF;AAGA,UAAM,EAAE,KAAK,KAAK,IAAI,KAAK,cAAc,mBAAmB,gBAAgB;AAE5E,UAAM,oBAAoB,kBAAkB,SAAS;AAErD,WAAO;AAAA,MACL;AAAA,MACA;AAAA,MACA;AAAA,MACA;AAAA,MACA;AAAA,MACA;AAAA,MACA;AAAA,MACA;AAAA,MACA;AAAA,MACA;AAAA,MACA,cAAc;AAAA;AAAA,IAChB;AAAA,EACF;AAAA;AAAA;AAAA;AAAA,EAKQ,cACN,mBACA,kBAC+B;AAC/B,UAAM,cAAc,IAAI,IAAI,gBAAgB;AAG5C,QAAI,MAAM;AACV,aAAS,IAAI,GAAG,IAAI,kBAAkB,QAAQ,KAAK;AACjD,YAAM,YAAY,YAAY,IAAI,kBAAkB,CAAC,CAAE,IAAI,IAAI;AAC/D,aAAO,YAAY,KAAK,KAAK,IAAI,CAAC;AAAA,IACpC;AAGA,QAAI,OAAO;AACX,aAAS,IAAI,GAAG,IAAI,KAAK,IAAI,iBAAiB,QAAQ,kBAAkB,MAAM,GAAG,KAAK;AACpF,cAAQ,IAAI,KAAK,KAAK,IAAI,CAAC;AAAA,IAC7B;AAEA,UAAM,OAAO,OAAO,IAAI,MAAM,OAAO;AAErC,WAAO,EAAE,KAAK,KAAK;AAAA,EACrB;AAAA;AAAA;AAAA;AAAA,EAKQ,eACN,cACA,gBACA,kBACQ;AACR,QAAI,CAAC,cAAc;AACjB,aAAO;AAAA,IACT;AAEA,QAAI,QAAQ;AACZ,UAAM,cAAc,aAAa,YAAY;AAC7C,UAAM,gBAAgB,eAAe,YAAY;AAGjD,UAAM,cAAc,IAAI,IAAI,YAAY,MAAM,KAAK,CAAC;AACpD,UAAM,gBAAgB,IAAI,IAAI,cAAc,MAAM,KAAK,CAAC;AACxD,UAAM,eAAe,IAAI,IAAI,CAAC,GAAG,WAAW,EAAE,OAAO,OAAK,cAAc,IAAI,CAAC,CAAC,CAAC;AAC/E,UAAM,QAAQ,oBAAI,IAAI,CAAC,GAAG,aAAa,GAAG,aAAa,CAAC;AAExD,QAAI,MAAM,OAAO,GAAG;AAClB,eAAU,aAAa,OAAO,MAAM,OAAQ;AAAA,IAC9C;AAGA,QAAI,kBAAkB;AACpB,UAAI,eAAe;AACnB,iBAAW,WAAW,kBAAkB;AACtC,YAAI,YAAY,SAAS,QAAQ,YAAY,CAAC,GAAG;AAC/C;AAAA,QACF;AAAA,MACF;AACA,eAAU,eAAe,iBAAiB,SAAU;AAAA,IACtD;AAEA,WAAO,KAAK,IAAI,OAAO,CAAG;AAAA,EAC5B;AAAA;AAAA;AAAA;AAAA,EAKQ,iBACN,cACA,mBACmB;AACnB,QAAI,aAAa,WAAW,GAAG;AAC7B,aAAO;AAAA,QACL,WAAW;AAAA,QACX,QAAQ;AAAA,QACR,SAAS;AAAA,QACT,KAAK;AAAA,QACL,MAAM;AAAA,QACN,SAAS;AAAA,QACT,iBAAiB;AAAA,MACnB;AAAA,IACF;AAEA,UAAM,eAAe,aAAa;AAGlC,UAAM,YAAY,aAAa,OAAO,CAAC,KAAK,MAAM,MAAM,EAAE,WAAW,CAAC,IAAI;AAC1E,UAAM,SAAS,aAAa,OAAO,CAAC,KAAK,MAAM,MAAM,EAAE,QAAQ,CAAC,IAAI;AACpE,UAAM,UAAU,aAAa,OAAO,CAAC,KAAK,MAAM,MAAM,EAAE,SAAS,CAAC,IAAI;AACtE,UAAM,MAAM,aAAa,OAAO,CAAC,KAAK,MAAM,MAAM,EAAE,gBAAgB,CAAC,IAAI;AACzE,UAAM,OAAO,aAAa,OAAO,CAAC,KAAK,MAAM,MAAM,EAAE,MAAM,CAAC,IAAI;AAGhE,UAAM,UAAU,aAAa,OAAO,OAAK,EAAE,iBAAiB,EAAE,SAAS;AAGvE,UAAM,kBAAkB,oBAAoB;AAE5C,WAAO;AAAA,MACL;AAAA,MACA;AAAA,MACA;AAAA,MACA;AAAA,MACA;AAAA,MACA;AAAA,MACA;AAAA,IACF;AAAA,EACF;AAAA;AAAA;AAAA;AAAA,EAKA,MAAM,eACJ,oBACA,SAA2B,CAAC,GACX;AACjB,UAAM,UAAU,MAAM,KAAK,SAAS,oBAAoB,MAAM;AAC9D,UAAM,EAAE,IAAI,IAAI,SAAS,OAAO,SAAS,MAAM,IAAI;AAEnD,UAAM,SAAS;AAAA;AAAA;AAAA;AAAA,qBAIE,CAAC;AAAA,uBACC,SAAS,YAAY,UAAU;AAAA,mBACnC,SAAS,YAAY,UAAU;AAAA,uBAC3B,mBAAmB,MAAM;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,oBAM5B,QAAQ,UAAU,QAAQ,CAAC,CAAC;AAAA,iBAC/B,QAAQ,OAAO,QAAQ,CAAC,CAAC;AAAA,mBACvB,QAAQ,QAAQ,QAAQ,CAAC,CAAC;AAAA,cAC/B,QAAQ,IAAI,QAAQ,CAAC,CAAC;AAAA,eACrB,QAAQ,KAAK,QAAQ,CAAC,CAAC;AAAA,oBAClB,QAAQ,UAAU,KAAK,QAAQ,CAAC,CAAC;AAAA,4BACzB,QAAQ,gBAAgB,QAAQ,CAAC,CAAC;AAAA;AAAA;AAAA;AAAA;AAAA,EAK5D,KAAK,yBAAyB,OAAO,CAAC;AAAA;AAAA;AAAA,EAGtC,KAAK,mBAAmB,OAAO,CAAC;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,EAWhC,KAAK;AAEH,WAAO;AAAA,EACT;AAAA;AAAA;AAAA;AAAA,EAKQ,yBAAyB,SAAoC;AACnE,UAAM,EAAE,WAAW,QAAQ,SAAS,QAAQ,IAAI;AAEhD,QAAI,WAAW,KAAK;AAClB,aAAO;AAAA,IACT,WAAW,WAAW,MAAM;AAC1B,aAAO;AAAA,IACT,WAAW,WAAW,KAAK;AACzB,aAAO;AAAA,IACT,OAAO;AACL,aAAO;AAAA,IACT;AAAA,EACF;AAAA;AAAA;AAAA;AAAA,EAKQ,mBAAmB,SAAoC;AAC7D,UAAM,kBAA4B,CAAC;AACnC,UAAM,EAAE,WAAW,QAAQ,SAAS,SAAS,gBAAgB,IAAI;AAEjE,QAAI,YAAY,KAAK;AACnB,sBAAgB,KAAK,0GAAqG;AAAA,IAC5H;AAEA,QAAI,SAAS,KAAK;AAChB,sBAAgB,KAAK,wGAAmG;AAAA,IAC1H;AAEA,QAAI,UAAU,KAAK;AACjB,sBAAgB,KAAK,sGAAiG;AAAA,IACxH;AAEA,QAAI,kBAAkB,KAAM;AAC1B,sBAAgB,KAAK,oGAA+F;AAAA,IACtH;AAEA,QAAI,YAAY,OAAO,SAAS,KAAK;AACnC,sBAAgB,KAAK,kGAA6F;AAAA,IACpH;AAEA,QAAI,SAAS,OAAO,YAAY,KAAK;AACnC,sBAAgB,KAAK,2FAAsF;AAAA,IAC7G;AAEA,WAAO,gBAAgB,SAAS,IAC5B,gBAAgB,KAAK,IAAI,IACzB;AAAA,EACN;AACF;AAKO,SAAS,gCAAoD;AAClE,SAAO;AAAA,IACL;AAAA,MACE,OAAO;AAAA,MACP,kBAAkB,CAAC,yBAAyB,sBAAsB;AAAA,MAClE,gBAAgB;AAAA,MAChB,kBAAkB,CAAC,WAAW,iBAAiB,WAAW;AAAA,IAC5D;AAAA,IACA;AAAA,MACE,OAAO;AAAA,MACP,kBAAkB,CAAC,sBAAsB,gBAAgB;AAAA,MACzD,gBAAgB;AAAA,MAChB,kBAAkB,CAAC,gBAAgB,SAAS;AAAA,IAC9C;AAAA,IACA;AAAA,MACE,OAAO;AAAA,MACP,kBAAkB,CAAC,uBAAuB,0BAA0B,kBAAkB;AAAA,MACtF,gBAAgB;AAAA,MAChB,kBAAkB,CAAC,WAAW,YAAY,YAAY;AAAA,IACxD;AAAA,IACA;AAAA,MACE,OAAO;AAAA,MACP,kBAAkB,CAAC,oBAAoB,uBAAuB,wBAAwB;AAAA,MACtF,gBAAgB;AAAA,MAChB,kBAAkB,CAAC,QAAQ,aAAa,QAAQ,OAAO;AAAA,IACzD;AAAA,EACF;AACF;;;ACzZO,SAAS,mBAAmB,OAAe,YAA0C;AAC1F,QAAM,SAA+B,CAAC;AAEtC,QAAM,cAAc;AAAA,IAClB;AAAA,IACA;AAAA,IACA;AAAA,IACA;AAAA,IACA;AAAA,IACA;AAAA,IACA;AAAA,IACA;AAAA,IACA;AAAA,IACA;AAAA,EACF;AAEA,WAAS,IAAI,GAAG,IAAI,OAAO,KAAK;AAC9B,UAAM,YAAY,IAAI,YAAY;AAClC,UAAM,WAAW,YAAY,SAAS;AAEtC,WAAO,KAAK;AAAA,MACV,OAAO;AAAA,QACL,IAAI,mBAAmB,CAAC;AAAA,QACxB,MAAM,GAAG,QAAQ,yBAAyB,CAAC;AAAA,QAC3C,OAAO;AAAA,QACP,MAAM,QAAQ,CAAC;AAAA,QACf,QAAQ;AAAA,UACN,OAAO,sBAAsB,KAAK,MAAM,IAAI,EAAE,CAAC;AAAA,UAC/C,MAAM;AAAA,QACR;AAAA,QACA,UAAU;AAAA,UACR,aAAa;AAAA,UACb,UAAU,CAAC,MAAM,YAAY,OAAO,SAAS,UAAU,EAAE,IAAI,CAAC;AAAA,QAChE;AAAA,MACF;AAAA,MACA,WAAW,wBAAwB,UAAU;AAAA,IAC/C,CAAC;AAAA,EACH;AAEA,SAAO;AACT;AAKA,SAAS,wBAAwB,YAA8B;AAC7D,SAAO,MAAM,KAAK,EAAE,QAAQ,WAAW,GAAG,MAAM,KAAK,OAAO,IAAI,IAAI,CAAC;AACvE;AAKO,SAAS,sBAAsB,OAAwD;AAC5F,QAAM,aAAa;AAAA,IACjB;AAAA,IACA;AAAA,IACA;AAAA,IACA;AAAA,IACA;AAAA,IACA;AAAA,IACA;AAAA,IACA;AAAA,IACA;AAAA,IACA;AAAA,EACF;AAEA,QAAM,UAAmD,CAAC;AAE1D,WAAS,IAAI,GAAG,IAAI,OAAO,KAAK;AAC9B,UAAM,OAAO,WAAW,IAAI,WAAW,MAAM,IAAI,UAAU,CAAC;AAC5D,YAAQ,KAAK;AAAA,MACX;AAAA,MACA,WAAW,wBAAwB,IAAI;AAAA;AAAA,IACzC,CAAC;AAAA,EACH;AAEA,SAAO;AACT;AAKA,SAAS,gBAAwB;AAC/B,MAAI,OAAO,YAAY,eAAe,QAAQ,aAAa;AACzD,UAAM,QAAQ,QAAQ,YAAY;AAClC,WAAO,MAAM,WAAW,OAAO;AAAA,EACjC;AACA,SAAO;AACT;AAKA,eAAsB,qBACpB,SACA,QAC0B;AAC1B,QAAM,UAAgC,CAAC;AACvC,QAAM,cAAc,cAAc;AAElC,UAAQ,IAAI,0BAAmB,QAAQ,IAAI,KAAK;AAEhD,aAAW,cAAc,OAAO,aAAa;AAC3C,YAAQ,IAAI,4BAAqB,UAAU,YAAY;AAGvD,UAAM,aAAa,mBAAmB,YAAY,OAAO,UAAU;AACnE,UAAM,UAAU,sBAAsB,OAAO,aAAa;AAG1D,QAAI,OAAO,cAAc,OAAO,aAAa,GAAG;AAC9C,YAAM,eAAe,mBAAmB,KAAK,IAAI,KAAK,UAAU,GAAG,OAAO,UAAU;AACpF,eAAS,IAAI,GAAG,IAAI,OAAO,YAAY,KAAK;AAC1C,cAAM,QAAQ,OAAO,aAAa,MAAM,GAAG,EAAE,CAAC;AAC9C,cAAM,QAAQ,eAAe,QAAQ,CAAC,GAAG,aAAa,CAAC,GAAG,OAAO,CAAC;AAAA,MACpE;AACA,YAAM,QAAQ,MAAM;AAAA,IACtB;AAGA,UAAM,cAAwB,CAAC;AAC/B,aAAS,MAAM,GAAG,MAAM,OAAO,MAAM,OAAO;AAC1C,YAAM,QAAQ,MAAM;AAEpB,YAAM,QAAQ,YAAY,IAAI;AAC9B,YAAM,QAAQ,OAAO,UAAU;AAC/B,YAAM,MAAM,YAAY,IAAI;AAE5B,kBAAY,KAAK,MAAM,KAAK;AAAA,IAC9B;AAEA,UAAM,gBAAgB,YAAY,OAAO,CAAC,KAAK,SAAS,MAAM,MAAM,CAAC,IAAI,YAAY;AACrF,YAAQ,KAAK;AAAA,MACX,WAAW;AAAA,MACX,WAAW;AAAA,MACX,UAAU;AAAA,MACV,YAAY,cAAc,gBAAgB;AAAA,MAC1C,UAAU,cAAc;AAAA,MACxB,UAAU;AAAA,QACR,SAAS,KAAK,IAAI,GAAG,WAAW;AAAA,QAChC,SAAS,KAAK,IAAI,GAAG,WAAW;AAAA,QAChC,QAAQ,KAAK,KAAK,YAAY,OAAO,CAAC,KAAK,SAAS,MAAM,KAAK,IAAI,OAAO,eAAe,CAAC,GAAG,CAAC,IAAI,YAAY,MAAM;AAAA,MACtH;AAAA,IACF,CAAC;AAGD,UAAM,cAAwB,CAAC;AAC/B,aAAS,MAAM,GAAG,MAAM,OAAO,MAAM,OAAO;AAC1C,iBAAW,SAAS,SAAS;AAC3B,cAAM,QAAQ,YAAY,IAAI;AAC9B,cAAM,UAAU,MAAM,QAAQ,eAAe,MAAM,WAAW,OAAO,CAAC;AACtE,cAAM,MAAM,YAAY,IAAI;AAE5B,oBAAY,KAAK,MAAM,KAAK;AAG5B,YAAI,QAAQ,WAAW,KAAK,aAAa,GAAG;AAC1C,kBAAQ,KAAK,sDAA4C,UAAU,SAAS;AAAA,QAC9E;AAAA,MACF;AAAA,IACF;AAEA,UAAM,gBAAgB,YAAY,OAAO,CAAC,KAAK,SAAS,MAAM,MAAM,CAAC,IAAI,YAAY;AACrF,YAAQ,KAAK;AAAA,MACX,WAAW;AAAA,MACX,WAAW;AAAA,MACX,UAAU;AAAA,MACV,YAAY,MAAO;AAAA;AAAA,MACnB,UAAU,cAAc;AAAA,MACxB,UAAU;AAAA,QACR,eAAe,QAAQ;AAAA,QACvB,SAAS,KAAK,IAAI,GAAG,WAAW;AAAA,QAChC,SAAS,KAAK,IAAI,GAAG,WAAW;AAAA,QAChC,SAAS,YAAY,KAAK,CAAC,GAAG,MAAM,IAAI,CAAC,EAAE,KAAK,MAAM,YAAY,SAAS,IAAI,CAAC;AAAA,MAClF;AAAA,IACF,CAAC;AAAA,EACH;AAEA,QAAM,aAAa,KAAK,IAAI,GAAG,QAAQ,IAAI,OAAK,EAAE,YAAY,CAAC,CAAC;AAChE,QAAM,sBAAsB,QACzB,OAAO,OAAK,EAAE,cAAc,QAAQ,EACpC,OAAO,CAAC,KAAK,MAAM,MAAM,EAAE,YAAY,CAAC,IACzC,QAAQ,OAAO,OAAK,EAAE,cAAc,QAAQ,EAAE;AAEhD,QAAM,mBAAmB,QACtB,OAAO,OAAK,EAAE,cAAc,QAAQ,EACpC,OAAO,CAAC,KAAK,MAAM,MAAM,EAAE,UAAU,CAAC,IACvC,QAAQ,OAAO,OAAK,EAAE,cAAc,QAAQ,EAAE;AAGhD,MAAI,iBAAiB;AACrB,MAAI,sBAAsB,KAAM;AAC9B,qBAAiB;AAAA,EACnB,WAAW,sBAAsB,KAAK;AACpC,qBAAiB;AAAA,EACnB,OAAO;AACL,qBAAiB;AAAA,EACnB;AAEA,MAAI,mBAAmB,KAAK;AAC1B,sBAAkB;AAAA,EACpB;AAEA,SAAO;AAAA,IACL,aAAa,QAAQ;AAAA,IACrB;AAAA,IACA;AAAA,IACA,SAAS;AAAA,MACP;AAAA,MACA;AAAA,MACA,cAAc;AAAA,MACd;AAAA,IACF;AAAA,IACA,WAAW,oBAAI,KAAK;AAAA,EACtB;AACF;AAKA,eAAsB,sBACpB,SACA,QAC0B;AAC1B,QAAM,UAAgC,CAAC;AAEvC,UAAQ,IAAI,0CAAmC,QAAQ,IAAI,KAAK;AAEhE,aAAW,cAAc,OAAO,aAAa;AAC3C,YAAQ,IAAI,4BAAqB,UAAU,YAAY;AAGvD,UAAM,aAAa,mBAAmB,YAAY,OAAO,UAAU,EAAE,IAAI,OAAK,EAAE,KAAK;AACrF,UAAM,UAAU,sBAAsB,OAAO,aAAa;AAG1D,UAAM,aAAuB,CAAC;AAC9B,aAAS,MAAM,GAAG,MAAM,OAAO,MAAM,OAAO;AAC1C,YAAM,QAAQ,YAAY,IAAI;AAC9B,YAAM,QAAQ,MAAM,UAAU;AAC9B,YAAM,MAAM,YAAY,IAAI;AAE5B,iBAAW,KAAK,MAAM,KAAK;AAAA,IAC7B;AAEA,UAAM,eAAe,WAAW,OAAO,CAAC,KAAK,SAAS,MAAM,MAAM,CAAC,IAAI,WAAW;AAClF,YAAQ,KAAK;AAAA,MACX,WAAW;AAAA,MACX,WAAW;AAAA,MACX,UAAU;AAAA,MACV,YAAY,cAAc,eAAe;AAAA,MACzC,UAAU,cAAc;AAAA,IAC1B,CAAC;AAGD,UAAM,cAAwB,CAAC;AAC/B,aAAS,MAAM,GAAG,MAAM,OAAO,MAAM,OAAO;AAC1C,iBAAW,SAAS,SAAS;AAC3B,cAAM,QAAQ,YAAY,IAAI;AAC9B,cAAM,UAAU,MAAM,QAAQ,OAAO,MAAM,MAAM,OAAO,CAAC;AACzD,cAAM,MAAM,YAAY,IAAI;AAE5B,oBAAY,KAAK,MAAM,KAAK;AAAA,MAC9B;AAAA,IACF;AAEA,UAAM,gBAAgB,YAAY,OAAO,CAAC,KAAK,SAAS,MAAM,MAAM,CAAC,IAAI,YAAY;AACrF,YAAQ,KAAK;AAAA,MACX,WAAW;AAAA,MACX,WAAW;AAAA,MACX,UAAU;AAAA,MACV,YAAY,MAAO;AAAA,MACnB,UAAU,cAAc;AAAA,IAC1B,CAAC;AAAA,EACH;AAEA,QAAM,qBAAqB,QACxB,OAAO,OAAK,EAAE,cAAc,OAAO,EACnC,OAAO,CAAC,KAAK,MAAM,MAAM,EAAE,YAAY,CAAC,IACzC,QAAQ,OAAO,OAAK,EAAE,cAAc,OAAO,EAAE;AAE/C,QAAM,mBAAmB,QACtB,OAAO,OAAK,EAAE,cAAc,QAAQ,EACpC,OAAO,CAAC,KAAK,MAAM,MAAM,EAAE,UAAU,CAAC,IACvC,QAAQ,OAAO,OAAK,EAAE,cAAc,QAAQ,EAAE;AAEhD,SAAO;AAAA,IACL,aAAa,QAAQ;AAAA,IACrB;AAAA,IACA;AAAA,IACA,SAAS;AAAA,MACP,qBAAqB;AAAA,MACrB;AAAA,MACA,gBAAgB,mBAAmB,KAAK,yCAAyC;AAAA,IACnF;AAAA,IACA,WAAW,oBAAI,KAAK;AAAA,EACtB;AACF;AAKO,SAAS,eAAe,SAA8C;AAC3E,QAAM,iBAAyC,CAAC;AAChD,QAAM,SAAiD,CAAC;AAGxD,QAAM,aAAa,CAAC,UAAU,UAAU,OAAO;AAE/C,aAAW,aAAa,YAAY;AAClC,QAAI,iBAAiB;AACrB,QAAI,cAAc;AAElB,eAAW,UAAU,SAAS;AAC5B,YAAM,YAAY,OAAO,QAAQ,OAAO,OAAK,EAAE,cAAc,SAAS;AACtE,UAAI,UAAU,SAAS,GAAG;AACxB,cAAM,gBAAgB,UAAU,OAAO,CAAC,KAAK,MAAM,MAAM,EAAE,YAAY,CAAC,IAAI,UAAU;AACtF,YAAI,gBAAgB,gBAAgB;AAClC,2BAAiB;AACjB,wBAAc,OAAO;AAAA,QACvB;AAAA,MACF;AAAA,IACF;AAEA,QAAI,aAAa;AACf,qBAAe,SAAS,IAAI;AAAA,IAC9B;AAAA,EACF;AAGA,aAAW,WAAW,SAAS;AAC7B,WAAO,QAAQ,WAAW,IAAI,CAAC;AAE/B,eAAW,WAAW,SAAS;AAC7B,UAAI,QAAQ,gBAAgB,QAAQ,aAAa;AAC/C,cAAM,SAAS,QAAQ,QAAQ,sBAAsB,QAAQ,QAAQ;AACrE,cAAM,mBAAmB,OAAO,QAAQ,WAAW;AACnD,YAAI,kBAAkB;AACpB,2BAAiB,QAAQ,WAAW,IAAI;AAAA,QAC1C;AAAA,MACF;AAAA,IACF;AAAA,EACF;AAGA,QAAM,kBAAkB;AAAA,IACtB,aAAa,QAAQ,KAAK,OAAK,EAAE,YAAY,SAAS,QAAQ,CAAC,GAAG,eACtD,QAAQ,CAAC,GAAG,cAAc;AAAA,IACtC,YAAY,eAAe,UAAU,QAAQ,CAAC,GAAG,eAAe;AAAA,IAChE,YAAY,eAAe,UAAU,QAAQ,CAAC,GAAG,eAAe;AAAA,EAClE;AAEA,SAAO;AAAA,IACL;AAAA,IACA,UAAU;AAAA,MACR;AAAA,MACA;AAAA,MACA;AAAA,IACF;AAAA,EACF;AACF;AAKO,SAAS,eAAe,YAAsC;AACnE,QAAM,EAAE,SAAS,SAAS,IAAI;AAE9B,MAAI,SAAS;AACb,YAAU,eAAc,oBAAI,KAAK,GAAE,YAAY,CAAC;AAAA;AAAA;AAGhD,YAAU;AACV,YAAU;AACV,YAAU;AAEV,aAAW,UAAU,SAAS;AAC5B,UAAM,aAAa,OAAO,QAAQ,oBAAoB,QAAQ,CAAC;AAC/D,UAAM,UAAU,OAAO,QAAQ,iBAAiB,QAAQ,CAAC;AACzD,UAAM,SAAS,OAAO,QAAQ,cAAc,QAAQ,CAAC,KAAK;AAC1D,UAAM,MAAM,OAAO,QAAQ;AAE3B,cAAU,KAAK,OAAO,WAAW,MAAM,UAAU,cAAc,OAAO,QAAQ,MAAM,QAAQ,GAAG;AAAA;AAAA,EACjG;AAEA,YAAU;AACV,aAAW,CAAC,WAAW,OAAO,KAAK,OAAO,QAAQ,SAAS,cAAc,GAAG;AAC1E,cAAU,OAAO,SAAS,OAAO,OAAO;AAAA;AAAA,EAC1C;AAEA,YAAU;AACV,YAAU,sBAAsB,SAAS,gBAAgB,WAAW;AAAA;AACpE,YAAU,qBAAqB,SAAS,gBAAgB,UAAU;AAAA;AAClE,YAAU,sBAAsB,SAAS,gBAAgB,UAAU;AAAA;AAEnE,YAAU;AACV,aAAW,UAAU,SAAS;AAC5B,cAAU,OAAO,OAAO,WAAW;AAAA;AAAA;AAEnC,eAAW,UAAU,OAAO,SAAS;AACnC,gBAAU,KAAK,OAAO,SAAS,OAAO,OAAO,SAAS;AAAA;AACtD,gBAAU,eAAe,OAAO,SAAS,QAAQ,CAAC,CAAC;AAAA;AACnD,gBAAU,iBAAiB,OAAO,WAAW,QAAQ,CAAC,CAAC;AAAA;AACvD,UAAI,OAAO,UAAU;AACnB,kBAAU,aAAa,OAAO,SAAS,QAAQ,CAAC,CAAC;AAAA;AAAA,MACnD;AACA,gBAAU;AAAA,IACZ;AAAA,EACF;AAEA,SAAO;AACT;AAKO,IAAM,2BAA4C;AAAA,EACvD,aAAa,CAAC,IAAI,IAAI,KAAK,GAAG;AAAA,EAC9B,YAAY;AAAA;AAAA,EACZ,eAAe;AAAA,EACf,GAAG;AAAA,EACH,MAAM;AAAA,EACN,YAAY;AACd;AAKO,IAAM,iCAAkD;AAAA,EAC7D,aAAa,CAAC,KAAK,KAAK,KAAM,KAAM,GAAK;AAAA,EACzC,YAAY;AAAA,EACZ,eAAe;AAAA,EACf,GAAG;AAAA,EACH,MAAM;AAAA,EACN,YAAY;AACd;","names":[]}